<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>evolutionary algorithms - Categoría - CastilloS</title>
        <link>https://castillosebastian.github.io/es/categories/evolutionary-algorithms/</link>
        <description>evolutionary algorithms - Categoría - CastilloS</description>
        <generator>Hugo -- gohugo.io</generator><language>es</language><managingEditor>castilloclaudiosebastian@gmail.com (Castillo Claudio Sebastian)</managingEditor>
            <webMaster>castilloclaudiosebastian@gmail.com (Castillo Claudio Sebastian)</webMaster><lastBuildDate>Thu, 01 Jun 2023 10:49:29 -0300</lastBuildDate><atom:link href="https://castillosebastian.github.io/es/categories/evolutionary-algorithms/" rel="self" type="application/rss+xml" /><item>
    <title>Feature Selection: Intro</title>
    <link>https://castillosebastian.github.io/es/feature_selection/</link>
    <pubDate>Thu, 01 Jun 2023 10:49:29 -0300</pubDate>
    <author>Castillo Claudio Sebastian</author>
    <guid>https://castillosebastian.github.io/es/feature_selection/</guid>
    <description><![CDATA[<p>La selección de características es un tema importante dentro del <strong>aprendizaje automático</strong> (<strong>marchine learning</strong>) debido a la dimensionalidad que presentan los datos dentro de este dominio. Frecuentemente los individuos con los que se trabaja están representados por vectores de N dimensiones (i.e.regularmente mediciones de un proceso o fenómeno), que se necesitan procesar para resolver un problema. Estas dimensiones muchas veces superan la cantidad de individuos disponibles planteando serios problemas a los algoritmos de aprendizaje, cuya complejidad (en términos de parámetros) crece conforme crece la dimensionalidad.</p>
<p>Ante esta situación aparece la necesidad de buscar un subconjunto de características apropiado que permita atacar el problema de manera efectiva. Si los problemas en ML crecen exponencialmente con las dimensiones de los datos (tenemos la fórmula donde cada problema (2)N, si N = 50 el problema se vuelve intratable para búsquedas exhaustivas) se vuelven importante métodos que puedan abordar la dimensionalidad. Aparecen los métodos de optimización combinatoria.</p>
<p>Podemos agrupar esos métodos siguiendo tres enfoques en el diseño de la solución:</p>
<ul>
<li>se determina un conjunto de dimensiones y se busca maximizar una métrica de desempeño (e.g. precisión),</li>
<li>se busca el conjunto más pequeño de dimensiones que satisfaga cierto umbral de desempeño,</li>
<li>se busca el compromiso óptimo entre dimensionalidad y desempeño,</li>
</ul>]]></description>
</item>
</channel>
</rss>
