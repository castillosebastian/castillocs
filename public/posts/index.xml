<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>All Posts - CastilloS</title>
        <link>https://castillosebastian.github.io/posts/</link>
        <description>All Posts | CastilloS</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>castilloclaudiosebastian@gmail.com (Castillo Claudio Sebastian)</managingEditor>
            <webMaster>castilloclaudiosebastian@gmail.com (Castillo Claudio Sebastian)</webMaster><lastBuildDate>Fri, 01 Sep 2023 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://castillosebastian.github.io/posts/" rel="self" type="application/rss+xml" /><item>
    <title>Generative models: variational autoencoders</title>
    <link>https://castillosebastian.github.io/variational_autoencoders/</link>
    <pubDate>Fri, 01 Sep 2023 00:00:00 &#43;0000</pubDate>
    <author>Castillo Claudio Sebastian</author>
    <guid>https://castillosebastian.github.io/variational_autoencoders/</guid>
    <description><![CDATA[<p>Generative models are a class of statistical models that aim to learn the underlying data distribution from a given dataset. These models provide a way to generate new samples that are statistically similar to the training data. They have gained substantial attention in various domains, such as image generation, speech synthesis, and even drug discovery.</p>]]></description>
</item>
<item>
    <title>Responsible AI Tools</title>
    <link>https://castillosebastian.github.io/responsible_ai/</link>
    <pubDate>Thu, 01 Jun 2023 10:49:29 -0300</pubDate>
    <author>Castillo Claudio Sebastian</author>
    <guid>https://castillosebastian.github.io/responsible_ai/</guid>
    <description><![CDATA[<p>Responsible AI has become a crucial aspect of every Machine Learning project, underscoring the need for tools that promote the creation of fair and ethically sound models. In this post, we delve into some key concepts and replicate IBM&rsquo;s inFairness example solution to address bias in the &lsquo;Adult Income&rsquo; dataset. Beyond the technical configurations adopted, the intent to algorithmically address unfairness and the statistical pursuit of both overt and hidden bias in data are particularly noteworthy. These are the key insights we hope readers will take away from this post.</p>]]></description>
</item>
<item>
    <title>Justice Analitics</title>
    <link>https://castillosebastian.github.io/analitics_in_judiciary/</link>
    <pubDate>Thu, 01 Dec 2016 21:57:40 &#43;0800</pubDate>
    <author>CastilloS</author>
    <guid>https://castillosebastian.github.io/analitics_in_judiciary/</guid>
    <description><![CDATA[<p>This post chronicles the transformative journey that the Judiciary of Entre RÃ­os, Argentina, where I serve as Director, is undertaking in the realm of statistics.</p>]]></description>
</item>
</channel>
</rss>
