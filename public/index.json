[{"categories":["AI"],"content":"Dive into the intersection of biology-inspired algorithms and cutting-edge generative AI with this latest blog post. We explore how Genetic Algorithms (GAs), drawing inspiration from natural evolution, and Variational Autoencoders (VAEs), sophisticated generative models, team up to tackle some of machine learning’s toughest challenges: feature selection in highly dimensional, noisy, and imbalanced datasets. Discover practical insights from real-world experiments, learn why more data isn’t always better, and see how carefully tuned synthetic data generation can significantly boost predictive accuracy and model interpretability. This post is a preview of my master’s thesis, supervised by Dr. Matias Gerard and Dr. Leandro Vignolo, CONICET–CINCI. ","date":"2025-03-13","objectID":"/syntheticdata_and_featureselection/:0:0","tags":["Synthetic Data","Feature Selection","Machine Learning","Generative AI"],"title":"Unraveling Complexity: How Genetic Algorithms and Synthetic Data Enhance Feature Selection","uri":"/syntheticdata_and_featureselection/"},{"categories":["AI"],"content":"A pervasive problem: Feature selection Imagine you’re facing a mountain of data—a spreadsheet sprawling across thousands of columns but only a handful of meaningful rows. In machine learning, scenarios like these are surprisingly common, creating serious headaches for data scientists and researchers alike. The sheer volume of data isn’t always helpful; in fact, it often adds noise, redundancy, and complexity that can drown out the real signals you’re after. This is where the art of feature selection steps in. It’s like sorting through the noise to discover hidden gems—those crucial features that truly matter for predicting outcomes. Effective feature selection not only sharpens your model’s predictions but also simplifies it, making it easier to interpret and trust. ","date":"2025-03-13","objectID":"/syntheticdata_and_featureselection/:1:0","tags":["Synthetic Data","Feature Selection","Machine Learning","Generative AI"],"title":"Unraveling Complexity: How Genetic Algorithms and Synthetic Data Enhance Feature Selection","uri":"/syntheticdata_and_featureselection/"},{"categories":["AI"],"content":"Facing Real-World Challenges In textbooks, datasets seem neatly packaged and perfectly balanced. But real-world data can be messy: high-dimensional spaces, limited samples, imbalanced classes, and plenty of irrelevant noise. Imagine trying to pinpoint important details in thousands of irrelevant or redundant features—it’s like finding a needle in a noisy, high-dimensional haystack. Typically, we tackle this with methods like: Filter Methods: Quick but might overlook feature interdependencies. Wrapper Methods: Effective but computationally expensive. Embedded Methods: Balanced approaches, integrating feature selection directly into the model training. But what if the problem is especially complex—like microarray datasets with tens of thousands of features but fewer than a hundred samples? Traditional methods often stumble here, struggling to reliably distinguish the meaningful features from noise. As datasets grow increasingly complex, the limitations of traditional approaches become glaringly apparent, demanding innovative solutions. ","date":"2025-03-13","objectID":"/syntheticdata_and_featureselection/:2:0","tags":["Synthetic Data","Feature Selection","Machine Learning","Generative AI"],"title":"Unraveling Complexity: How Genetic Algorithms and Synthetic Data Enhance Feature Selection","uri":"/syntheticdata_and_featureselection/"},{"categories":["AI"],"content":"Genetic Algorithms to save the day To overcome these challenges, scientists often turn to Genetic Algorithms (GAs)—an approach inspired by natural evolution. Think of a GA as nature’s own problem-solving toolkit: Population: Multiple candidate solutions (feature subsets) compete simultaneously. Selection: Better-performing solutions survive and propagate. Crossover \u0026 Mutation: Solutions evolve and improve over generations through recombination and random adjustments. Genetic Algorithms: Core Concepts GAs are population-based optimization techniques inspired by evolutionary biology. The algorithm typically maintains a population of candidate solutions (often called individuals), each of which is: Encoded in some representation (e.g., a binary string). Evaluated using a fitness function that measures how “good” the solution is. Recombined via genetic operators – selection, crossover, and mutation – to form a new population in the hope of discovering increasingly better solutions. ","date":"2025-03-13","objectID":"/syntheticdata_and_featureselection/:3:0","tags":["Synthetic Data","Feature Selection","Machine Learning","Generative AI"],"title":"Unraveling Complexity: How Genetic Algorithms and Synthetic Data Enhance Feature Selection","uri":"/syntheticdata_and_featureselection/"},{"categories":["AI"],"content":"1.1 Encoding the Solution Space A GA does not manipulate the raw data directly; instead, it uses an encoded representation. For example, in feature-selection problems with (n) features, each individual can be a binary vector of length (n), where a 1 indicates “this feature is chosen” and a 0 indicates “this feature is excluded.” This encoding is crucial because: It allows GA operators (mutation, crossover) to be clearly defined. It can significantly affect the GA’s convergence behavior if chosen poorly. ","date":"2025-03-13","objectID":"/syntheticdata_and_featureselection/:3:1","tags":["Synthetic Data","Feature Selection","Machine Learning","Generative AI"],"title":"Unraveling Complexity: How Genetic Algorithms and Synthetic Data Enhance Feature Selection","uri":"/syntheticdata_and_featureselection/"},{"categories":["AI"],"content":"1.2 Population-Based Search GAs evaluate many candidate solutions simultaneously rather than improving a single solution at a time. This population perspective promotes exploration of multiple regions in the solution space. Maintaining diversity in the population is essential: Low diversity risks premature convergence to suboptimal solutions. High diversity fosters broader exploration and increases the likelihood of finding better solutions. ","date":"2025-03-13","objectID":"/syntheticdata_and_featureselection/:3:2","tags":["Synthetic Data","Feature Selection","Machine Learning","Generative AI"],"title":"Unraveling Complexity: How Genetic Algorithms and Synthetic Data Enhance Feature Selection","uri":"/syntheticdata_and_featureselection/"},{"categories":["AI"],"content":"1.3 Fitness Function The fitness function is central to the GA’s search. It measures how well each individual (in its decoded form) solves the target problem. For feature selection, we typically combine two objectives: High predictive accuracy (or another performance metric) on a chosen classifier (e.g., an MLP). Fewer selected features, to encourage simpler, more interpretable solutions. ","date":"2025-03-13","objectID":"/syntheticdata_and_featureselection/:3:3","tags":["Synthetic Data","Feature Selection","Machine Learning","Generative AI"],"title":"Unraveling Complexity: How Genetic Algorithms and Synthetic Data Enhance Feature Selection","uri":"/syntheticdata_and_featureselection/"},{"categories":["AI"],"content":"1.4 Genetic Operators: Selection, Crossover, Mutation Selection: Chooses higher-fitness individuals to produce offspring. Popular schemes include roulette wheel, tournament, and window selection. Crossover: Mates two “parent” solutions to produce offspring, typically by splitting each parent’s encoding at one or more points and swapping segments. Mutation: Makes small random changes in an individual’s encoding—e.g., flipping bits in a binary vector. Mutation helps the GA explore new areas of the solution space. But GAs need enough data to properly evaluate candidate solutions. Limited or imbalanced datasets make this evaluation unreliable, risking poor feature selection. Moreover, without sufficient diversity and representation in the dataset, GAs can prematurely converge to suboptimal solutions, undermining their effectiveness. ","date":"2025-03-13","objectID":"/syntheticdata_and_featureselection/:3:4","tags":["Synthetic Data","Feature Selection","Machine Learning","Generative AI"],"title":"Unraveling Complexity: How Genetic Algorithms and Synthetic Data Enhance Feature Selection","uri":"/syntheticdata_and_featureselection/"},{"categories":["AI"],"content":"Synthetic Data: Fueling Genetic Algorithms Here’s the game changer: What if we could artificially expand datasets, creating more balanced and informative data points? Enter Variational Autoencoders (VAEs)—powerful generative models that learn data distributions and generate realistic synthetic samples. VAEs encode data into simplified representations and decode them back into new, similar-yet-novel data points. They tackle class imbalance by generating more examples of minority classes and reduce overfitting by adding diversity. VAEs achieve this by modeling latent variables in the data, capturing essential characteristics that define the dataset and enabling the generation of plausible new samples that enrich the original data. ","date":"2025-03-13","objectID":"/syntheticdata_and_featureselection/:4:0","tags":["Synthetic Data","Feature Selection","Machine Learning","Generative AI"],"title":"Unraveling Complexity: How Genetic Algorithms and Synthetic Data Enhance Feature Selection","uri":"/syntheticdata_and_featureselection/"},{"categories":["AI"],"content":"A Perfect Pair: VAEs and Genetic Algorithms Our approach integrates VAEs and GAs into a potent feature-selection framework: Generate Synthetic Data: We first use a VAE to expand the dataset, balancing classes and reducing noise. Run Genetic Algorithms: With more robust data, GAs effectively find the most predictive subsets of features. By combining these approaches, we amplify the strengths of both—ensuring better data representation and more accurate feature evaluation, ultimately producing superior results. ","date":"2025-03-13","objectID":"/syntheticdata_and_featureselection/:5:0","tags":["Synthetic Data","Feature Selection","Machine Learning","Generative AI"],"title":"Unraveling Complexity: How Genetic Algorithms and Synthetic Data Enhance Feature Selection","uri":"/syntheticdata_and_featureselection/"},{"categories":["AI"],"content":"What Did We Discover? When testing this combination across various datasets, the results were compelling: For datasets overwhelmed with noise, like the Madelon dataset, GA accuracy jumped significantly—from 75% to 83%—by leveraging synthetic data. The GA also zeroed in on fewer, truly important features, drastically improving interpretability. With highly imbalanced and complex datasets like gene-expression data, careful synthetic data generation significantly improved model stability and accuracy, especially benefiting underrepresented classes, ensuring models don’t overlook rare yet critical signals. Interestingly, more synthetic data isn’t always better. There’s an optimal amount of synthetic data, beyond which performance begins to degrade—highlighting the importance of balance and quality. Excessive synthetic data can lead to overlapping distributions or diluted signals, emphasizing the delicate balance required in data augmentation. ","date":"2025-03-13","objectID":"/syntheticdata_and_featureselection/:6:0","tags":["Synthetic Data","Feature Selection","Machine Learning","Generative AI"],"title":"Unraveling Complexity: How Genetic Algorithms and Synthetic Data Enhance Feature Selection","uri":"/syntheticdata_and_featureselection/"},{"categories":["AI"],"content":"Lessons from Our Experiments Several practical insights emerged: Quality over Quantity: Excess synthetic data can introduce confusion, emphasizing the importance of an optimal, tailored approach. Simpler Models Can Excel: Surprisingly, deeper neural networks weren’t always better. Sometimes, a simpler VAE architecture performed best, balancing complexity and efficiency. Careful Tuning Is Essential: Class weighting, feature pre-selection, and controlled generation methods significantly improved outcomes on difficult datasets, showcasing that meticulous tuning often outweighs raw computational power. Context Matters: Results varied significantly across different datasets, reinforcing the importance of tailoring methods to the specific characteristics of each problem. ","date":"2025-03-13","objectID":"/syntheticdata_and_featureselection/:7:0","tags":["Synthetic Data","Feature Selection","Machine Learning","Generative AI"],"title":"Unraveling Complexity: How Genetic Algorithms and Synthetic Data Enhance Feature Selection","uri":"/syntheticdata_and_featureselection/"},{"categories":["AI"],"content":"Where Do We Go Next? Combining genetic algorithms with synthetic data generation doesn’t just solve challenging feature-selection problems—it also opens doors to more reliable, interpretable machine learning models. Future explorations might involve advanced generative models (like diffusion models) or even multi-objective genetic algorithms to optimize additional factors beyond accuracy, such as computational cost, interpretability, or fairness. Additionally, integrating hybrid approaches like combining VAEs with other generative or reinforcement learning methods could further enhance the quality and usability of synthetic data. In short, by carefully merging biological inspiration with artificial creativity, we can build models that not only learn better but also make sense out of complex data landscapes—ensuring that our predictions are both robust and trustworthy. Through ongoing innovation and careful experimentation, the synergy between genetic algorithms and synthetic data promises to reshape how we approach complex machine learning challenges, unlocking new possibilities across diverse fields and applications. Bibliography Goldberg, David E. 1989. Genetic Algorithms in Search, Optimization, and Machine Learning. New York, NY, USA: Addison-Wesley. Kingma, Diederik P., and Max Welling. 2019. “An Introduction to Variational Autoencoders.” Foundations and Trends® in Machine Learning 12 (4): 307–92. https://doi.org/10.1561/2200000056. Vignolo, Leandro D., and Matias F. Gerard. 2017. “Evolutionary Local Improvementon Genetic Algorithms for Feature Selection.” In 2017 XLIII Latin American Computer Conference (CLEI), 1–8. Cordoba: IEEE. https://doi.org/10.1109/CLEI.2017.8226467. Zhang, Rui, Feiping Nie, Xuelong Li, and Xian Wei. 2019. “Feature Selection with Multi-View Data: A Survey.” Information Fusion 50 (October): 158–67. https://doi.org/10.1016/j.inffus.2018.11.019. Photo by Tim Mossholder on Unsplash ","date":"2025-03-13","objectID":"/syntheticdata_and_featureselection/:8:0","tags":["Synthetic Data","Feature Selection","Machine Learning","Generative AI"],"title":"Unraveling Complexity: How Genetic Algorithms and Synthetic Data Enhance Feature Selection","uri":"/syntheticdata_and_featureselection/"},{"categories":["AI"],"content":"In the ever-evolving landscape of Artificial Intelligence, a groundbreaking category of technologies known as foundation models is reshaping our interaction with the digital world. These models, which encompass the broad and powerful class of Large Language Models (LLMs), are built on expansive datasets, enabling them to perform an astonishing array of tasks. From engaging in human-like dialogues and answering complex questions to composing music and generating video content, LLMs are rapidly becoming specialized powerhouses in AI. Their versatility allows for remarkable applications that stretch the bounds of creativity and problem-solving. Through this series of posts, we will embark on a journey to uncover the myriad applications of LLMs across different domains, showcasing their transformative potential in reshaping industries and enhancing human capabilities. ","date":"2024-04-01","objectID":"/fundational_models/:0:0","tags":["LLM","Fundational Models","GenerativeAI","NLP","Transformer"],"title":"Large Language Models and Expert Assistants","uri":"/fundational_models/"},{"categories":["AI"],"content":"Foundation models disruption What happened with the emergence of Large Language Models (LLMs) that caused a profound impact in the relatively niche AI community, and how did this ripple effect extend into various spheres of public life? To understand this transformation, we must explore the roots from which LLMs have sprung and the distinctive features that set them apart from their predecessors. At their core, LLMs are not a radical departure from the well-established principles of deep neural networks (DNNs). For decades, DNNs have been instrumental in advancing a range of technologies, from image and speech recognition to natural language processing (NLP). A notable milestone in this field dates back to 2012 with the introduction of AlexNet, a type of DNN that uses convolutions, in the ImageNet Large Scale Visual Recognition Challenge. It significantly outperformed its competitors, marking the beginning of the deep learning revolution, supported by advanced infrastructure such as GPUs. However, despite their technological significance, DNNs remained largely within the domain of specialists and enthusiasts, rarely capturing the public’s imagination or expectation. The landscape began to change as researchers and engineers focused on leveraging DNNs for language-based applications. Early successes in language technologies, such as machine translation and simple chatbots, demonstrated the potential to create tools that could tackle specific, task-oriented problems with solutions that mimicked human-like understanding and responses. Yet, these technologies, while impressive, often fell short of replicating the depth and nuance of human cognitive abilities in language. A significant leap in the evolution of AI for language processing came with the development of the Transformer architecture. Just as AlexNet had marked a turning point in image recognition by harnessing the power of Convolutional Neural Networks (CNNs), the introduction of Transformers (Vaswani et al., 2017), revolutionized natural language processing. This was a pivotal moment in AI’s evolution, leading directly to the creation of LLMs. LLMs were not just incremental improvements; they represented a mayor step forward. By training on vastly larger datasets and integrating a more complex and nuanced understanding of language, made possible by the Transformer architecture, LLMs began to achieve — and in many cases, surpass — human-like capabilities across a wide range of linguistic domains. The saga of OpenAI's Generative Pre-trained Transformer The history of the evolution of the Generative Pre-trained Transformer (GPT) series by OpenAI is a important journey through recent advancements in artificial intelligence and natural language processing. From its inception, the GPT series has been at the forefront of demonstrating the emergent properties and scaling laws that underlie large language models (LLMs). ","date":"2024-04-01","objectID":"/fundational_models/:1:0","tags":["LLM","Fundational Models","GenerativeAI","NLP","Transformer"],"title":"Large Language Models and Expert Assistants","uri":"/fundational_models/"},{"categories":["AI"],"content":"GPT-1: The Foundation During the 2018, OpenAI publish the paper “Improving Language Understanding by Generative Pre-Training”. The first in the series, GPT-1, laid the groundwork for utilizing unsupervised learning to pre-train a language model on a large corpus of text. It demonstrated that pre-training followed by task-specific fine-tuning could achieve remarkable performance across a variety of NLP tasks, even with fewer data for supervised training. This model set the stage for the power of transformers in language understanding and generation. ","date":"2024-04-01","objectID":"/fundational_models/:1:1","tags":["LLM","Fundational Models","GenerativeAI","NLP","Transformer"],"title":"Large Language Models and Expert Assistants","uri":"/fundational_models/"},{"categories":["AI"],"content":"GPT-2: Scaling Up and Emergent Abilities One year later, a second work came to ligth with the publication of “Language Models are Unsupervised Multitask Learners”. In this new experiment, PT-2 significantly increased the scale, with 1.5 billion parameters. OpenAI highlighted the model’s ability to generate coherent and surprisingly nuanced text passages, perform rudimentary reading comprehension, machine translation, and even solve some types of common sense reasoning without task-specific training. One of the seminal findings from GPT-2’s development was the demonstration of emergent abilities; as the model size increased, it began to exhibit new behaviors and capabilities that were not directly taught. ","date":"2024-04-01","objectID":"/fundational_models/:1:2","tags":["LLM","Fundational Models","GenerativeAI","NLP","Transformer"],"title":"Large Language Models and Expert Assistants","uri":"/fundational_models/"},{"categories":["AI"],"content":"GPT-3: The Power of Scale By the 2020, with the publication of the paper “Language Models are Few-Shot Learners” and the presentation of GPT-3, OpenAI expanded the model to an unprecedented 175 billion parameters. This leap forward demonstrated the “scaling laws” in AI, where increasing the model size, data, and compute led to predictable improvements in performance. GPT-3 showcased remarkable few-shot learning abilities, where the model could understand and perform tasks with just a few examples provided in the prompt. This model emphasized the potential of LLMs to generalize across tasks without task-specific fine-tuning, a significant breakthrough in AI research. As a result, LLMs have evolved beyond the realm of task-specific tools to become generalized platforms capable of learning and adapting to an unprecedented breadth of applications. From writing and summarizing texts to generating creative content and engaging in sophisticated dialogues, these platforms have demonstrated flexibility and depth previously unimaginable. They have transitioned from being a subject of academic interest to a cornerstone of new products and services that touch many aspects of our daily lives. Yet, despite these advancements, LLMs face critical challenges that could limit their effectiveness, particularly when deployed in domains where precision and current knowledge are essential. ","date":"2024-04-01","objectID":"/fundational_models/:1:3","tags":["LLM","Fundational Models","GenerativeAI","NLP","Transformer"],"title":"Large Language Models and Expert Assistants","uri":"/fundational_models/"},{"categories":["AI"],"content":"Foudational models and the need for truthfulness One of the most significant issues confronting Large Language Models is their tendency to “hallucinate” or generate factually incorrect or misleading information. This limitation stems primarily from the models’ design: they are trained on vast datasets of text from the internet, books, and other sources without any intrinsic mechanism to verify the truthfulness of the content they generate. Consequently, these models are susceptible to producing responses that might seem plausible but are factually incorrect, especially in expert domains such as law, finance, and healthcare where accuracy is crucial. This challenge highlights a critical gap in their ability to serve as reliable tools in experts and professional settings. The problem of hallucination in LLMs is closely tied to another critical challenge: access to factual information. LLMs are typically static models once trained, meaning they are not updated with new information unless retrained with new data. This static nature implies that they can quickly become outdated, further compounding the issue of generating incorrect or irrelevant information based on older data sets. The consequence of these issues is significant. In domains where expert knowledge and up-to-date information are paramount, reliance on LLMs without addressing these limitations can lead to decisions based on outdated or incorrect data, which can be detrimental in fields like healthcare, where patient outcomes can depend on the latest medical research, or in law, where legal precedents may shift over time. Addressing the problem of hallucination and the need for access to factual information is therefore crucial for the development of LLMs that are truly useful in professional settings. One promising approach to mitigate these problems is integrating LLMs with external databases or dynamic information sources that can provide accurate, up-to-date context for the model’s responses. ","date":"2024-04-01","objectID":"/fundational_models/:2:0","tags":["LLM","Fundational Models","GenerativeAI","NLP","Transformer"],"title":"Large Language Models and Expert Assistants","uri":"/fundational_models/"},{"categories":["AI"],"content":"The Role of External Databases in Improving LLM Responses The integration of external databases into the LLM workflow offers a dual advantage: it not only provides a direct link to factual and up-to-date information but also enables the model to learn from a broader and more current dataset than what was available during its initial training. By accessing external databases, LLMs can pull in the most current data relevant to a query, whether it involves recent legal statutes, current financial market trends, or the latest medical research. This capability ensures that the responses generated are not only contextually appropriate but also reflect the most accurate information available. The RAG architecture merges the power of pre-trained language models with the precision of information retrieval systems. This pattern typically involves two main components: Retriever: Before generating a response, the retriever component searches an external database to find relevant documents or data snippets that might contain pertinent information for answering the user’s query. This process is based on similarity measures between the query and the information stored in the database. Generator: Once the relevant information is retrieved, the generator component of the RAG takes over. This is usually a pre-trained language model, like those used in standard LLMs, which uses both the original query and the retrieved documents to generate a coherent and informed response. The generator is capable of synthesizing information from the retriever and the knowledge it has learned during pre-training, creating a response that is both accurate and contextually enriched. ","date":"2024-04-01","objectID":"/fundational_models/:3:0","tags":["LLM","Fundational Models","GenerativeAI","NLP","Transformer"],"title":"Large Language Models and Expert Assistants","uri":"/fundational_models/"},{"categories":["AI"],"content":"From Naive RAG to Agents We can trace the progression and evolution of RAG architectures through several key stages: Naive RAG, Advanced RAG, Modular RAG, and finally Agentic RAG (see:https://arxiv.org/abs/2312.10997) Naive RAG The earliest iterations of RAG, which we term as “Naive RAG,” focus primarily on the basic integration of retrieval mechanisms with generative models. In this setup, the retrieval component is straightforward, often fetching data directly related to the input query from a fixed database or set of documents. The generator then uses this retrieved information as additional context to produce responses. Although this approach enhances the model’s output by grounding it in retrieved documents, it is limited by the static nature of the retrieval process and the simplicity of its integration, which can lead to suboptimal context utilization and relevance issues in the responses. Advanced RAG Building on the foundations of Naive RAG, the “Advanced RAG” models incorporate more sophisticated retrieval techniques, such as using machine learning to improve the relevance of retrieved documents based on the query’s context and the ongoing interaction history. Advanced RAG also starts to utilize feedback mechanisms where the generator’s output can influence subsequent retrieval queries, creating a more dynamic interaction between the retrieval and generation processes. This allows the system to adapt more effectively to the nuances of a conversation or a complex query sequence, thereby improving the overall coherence and relevance of the generated content. Modular RAG “Modular RAG” architectures take the flexibility of RAG systems further by decoupling the retrieval and generation components to a greater extent, allowing for interchangeable modules that can be optimized independently. This modularity enables the integration of different retrieval or generator models depending on the specific requirements of a task or domain, such as using specialized databases for medical inquiries or financial records. Modular RAG systems can dynamically switch between different modules mid-conversation, providing tailored responses based on the most appropriate data source or generation strategy for each query. Agentic RAG The most advanced stage, “Agentic RAG,” introduces significant enhancements that imbue the system with greater agency capabilities. These RAG models are designed to not only retrieve and generate information but also to make autonomous decisions about which actions to take—such as when to retrieve more information, which sources to consult, and how to interact with other systems or databases to resolve complex queries. Agentic RAG systems are characterized by their ability to function more independently and their capacity to handle tasks that require higher levels of cognitive abilities and decision-making, similar to how a human expert might operate within specific domains. The evolution of RAG from Naive to Agentic models illustrates a trajectory towards increasingly sophisticated, adaptable, and intelligent systems capable of performing complex tasks across various domains with high levels of accuracy and reliability. These developments highlight the potential of RAG architectures to significantly enhance the practical utility of LLMs in real-world applications, especially in knowledge-intensive fields where up-to-date and precise information is crucial. The RAG model thus operates as a feedback loop between retrieval and generation, continually refining the information it pulls from external sources to improve the relevance and accuracy of its outputs. This mechanism makes RAG particularly useful in expert domains, where precision and up-to-date knowledge are crucial. ","date":"2024-04-01","objectID":"/fundational_models/:4:0","tags":["LLM","Fundational Models","GenerativeAI","NLP","Transformer"],"title":"Large Language Models and Expert Assistants","uri":"/fundational_models/"},{"categories":["AI"],"content":"Notes on building RAG-type assistants Core Reasoning Engine: At the heart of RAG-type systems are Large Language Models (LLMs) that acts as reasoning engines. This engines are enhanced by various modules that provides the necessary tools and factual information to function effectively. This setup positions the LLMs as more than just text generators; they serve as a dynamic reasoning units capable of complex generation processes when supplemented with the right tools. In this way, RAGs can be seen as a bridge between the vast knowledge stored in external databases and the reasoning capabilities of LLMs. Iterative Development Approach: It is critical to start with a basic design and then progressively advance to more sophisticated levels. This approach allows for full control over the application’s execution. Over time, as the system’s capabilities are proven and its reliability is established, you can allow the RAG to take more autonomous decisions. This gradual transition is important for ensuring the system remains robust and the project’s constraints (regarding response time) are met. Orchestration of Responses: Effective orchestration involves ensuring seamless integration of parametric information derived from the LLM’s inherent capabilities with the knowledge retrieved during the execution. In many scenarios, the LLM alone can handle responses effectively; however, the challenge lies in integrating this capability with dynamically retrieved external data to enhance the relevance and factual groundedness of responses. Handling API Unreliability: APIs, which serves as bridges to external data for retrieval and completion in the generation process, do not always perform as expected (or documented). Planning for unexpected outcomes and incorporating fallback mechanisms or alternatives strategies are essential. This foresight helps maintain the system’s performance and ensures consistent user experiences despite external failures. Building Effective Retrievers: The success of a RAG-type system heavily relies on the quality of the retrieval strategy. An effective retriever is essential to provide high-quality, relevant information to the LLM. This is akin to the adage “garbage in, garbage out” —feeding the LLM with poor quality or irrelevant data will lead to poor quality outputs. Therefore, developing sophisticated retrieval mechanisms that can accurately discern and fetch pertinent information is crucial for generating high-quality responses. Bibliography Krizhevsky, A., Sutskever, I., \u0026 Hinton, G. E. (2012). ImageNet Classification with Deep Convolutional Neural Networks. In Advances in Neural Information Processing Systems 25 (NIPS 2012). Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., \u0026 Polosukhin, I. (2017). Attention Is All You Need. In Advances in Neural Information Processing Systems 30 (NIPS 2017). Yunfan Gao et al., Retrieval-Augmented Generation for Large Language Models: A Survey, 2024. Pic by McDobbie Hu en Unsplash ","date":"2024-04-01","objectID":"/fundational_models/:5:0","tags":["LLM","Fundational Models","GenerativeAI","NLP","Transformer"],"title":"Large Language Models and Expert Assistants","uri":"/fundational_models/"},{"categories":["Genetic Algorithms"],"content":"In the rich theatre of Nature, few creatures exemplify the power of evolutionary optimization as strikingly as the hummingbird. Similarly, in the field of artificial intelligence, Genetic Algorithms stand among the select few that have successfully harnessed the principles of evolution for optimization. In this post, I will discuss these techniques that solve complex problems through an evolutionary process, leading to optimal or near-optimal solutions. ","date":"2023-10-01","objectID":"/genetic_algorithms/:0:0","tags":["evolutionary algorithms","heuristic search","machine learning","optimization"],"title":"Can we imitate Nature's evolutionary abilities? ","uri":"/genetic_algorithms/"},{"categories":["Genetic Algorithms"],"content":"GENETIC ALGORITHMS Few creatures exemplify the power of evolutionary optimization as strikingly as the hummingbird. With its astonishing ability to hover in place and dart with unparalleled agility, this little bird serves as a living testament to the power of natural selection in fine-tuning species for specific ecological niches. Much like this remarkable creature, Genetic Algorithms (GA) stand as a testament to the ingenuity of artificial intelligence. These algorithms, part of the broader field of evolutionary computing, harness the principles of natural evolution to find optimal or near-optimal solutions to complex problems. Just as the hummingbird has evolved to become a master of aerodynamic efficiency, Genetic Algorithms evolve candidate solutions to arrive at the best possible answer, making them invaluable tools in various sectors from engineering to data science. ","date":"2023-10-01","objectID":"/genetic_algorithms/:1:0","tags":["evolutionary algorithms","heuristic search","machine learning","optimization"],"title":"Can we imitate Nature's evolutionary abilities? ","uri":"/genetic_algorithms/"},{"categories":["Genetic Algorithms"],"content":"Some biological context related to GA Genetic algorithms, a subset of the field of evolutionary computing in artificial intelligence, draw their inspiration from Darwin’s theory of evolution to find the most fit solutions to complex problems. The concept of evolutionary computing itself dates back to the 1960s, initiated by Rechenberg’s work on ‘Evolution Strategies.’ It was further advanced by John Holland, who not only conceptualized Genetic Algorithms but also enriched the domain through his seminal book ‘Adaption in Natural and Artificial Systems’ published in 1975. Adding another layer to this, John Koza in 1992 employed genetic algorithms to evolve LISP programs for specific tasks, coining the term ‘genetic programming’ for his approach. As a nature-inspired procedure, Genetic Algorithms (GA) are fundamentally built upon key biological concepts. For instance, every living organism is composed of cells, each containing a uniform set of chromosomes. These chromosomes, essentially strings of DNA, act as blueprints for the entire organism. They consist of individual genes —blocks of DNA— that encode specific proteins. In simpler terms, each gene governs a particular trait, such as eye color, with various possible configurations for that trait, known as alleles. Each gene occupies a designated position on the chromosome, referred to as its locus. The full structure of an organism’s genetic material is called its genome, and a specific set of genes within that genome constitutes its genotype. This genotype, influenced by developments after birth, lays the foundation for the organism’s phenotype, shaping both its physical and mental attributes. Evolution chiefly involves generational changes, making reproduction another cornerstone in the understanding of GA. During natural reproduction, a process known as recombination or crossover occurs first, wherein genes from both parents merge to create a new chromosome, thus forming a new individual. This offspring may then undergo mutations, which are slight alterations in DNA elements, primarily induced by errors during the gene-copying process. Lastly, an organism’s fitness is gauged by its ability to survive and thrive throughout its lifetime, which -in the contexto of an optimization problems- means that the “fitness” of a particular solution is measured by how well it satisfies the set criteria or objectives of the problem at hand. ","date":"2023-10-01","objectID":"/genetic_algorithms/:1:1","tags":["evolutionary algorithms","heuristic search","machine learning","optimization"],"title":"Can we imitate Nature's evolutionary abilities? ","uri":"/genetic_algorithms/"},{"categories":["Genetic Algorithms"],"content":"The essence of human-like optimization When we talk about optimization, whether in business decisions or algorithmic computations, the ultimate aim is to enhance performance. As Goldberg (1989) explains: What are we trying to accomplish when we optimize? Optimization seeks to improve performance toward some optimal point or points. Note that this definition has two parts: 1) we seek improvement to approach some 2) optimal point. There is a clear distinction between the process of improvement and the destination or optimum itself. Yet, in judging optimization procedures, we commonly focus solely upon convergence (does the method reach the optimum?) and forget entirely about interim performance. These ideas are particularly crucial in Genetic Algorithms where we deal with complex search spaces comprising of all feasible solutions to a problem. Each solution can be represented as a point in this space and evaluated based on its ‘fitness’ or suitability to the problem at hand. Traditional perspectives on optimization often focus narrowly on convergence while overlooking the importance of intermediate performance levels. This inclination likely finds its roots in the calculus-based origins of optimization theories. However, such a viewpoint doesn’t fit naturally with complex systems or real-world decision-making scenarios, such as in business. Here, the emphasis isn’t necessarily on achieving a singular ‘best’ outcome but rather on making quality decisions within available resources. Success is often relative to competition and context, aiming for a ‘satisficing’ level of performance (Simon, 1969). Applying this more nuanced understanding of optimization to Genetic Algorithms means recognizing that the journey toward the optimal is as significant as the destination itself. Within the search space, GA operates by generating new potential solutions as evolution progresses, each with its own fitness value. The optimization process thus becomes dynamic, continuously updating as new points are discovered in the search space. In complex systems, the goal isn’t merely to locate an extreme value (minimum or maximum) but to progressively improve, even if reaching the ‘perfect’ optimum may be elusive. In sum, when using Genetic Algorithms for optimization, the objective extends beyond mere convergence to an optimal point. The focus is also on the quality of interim solutions, which is essential for handling complex systems where ‘good enough’ often suffices. It’s not merely about finding the best solution but about consistently striving for better ones.\" ","date":"2023-10-01","objectID":"/genetic_algorithms/:1:2","tags":["evolutionary algorithms","heuristic search","machine learning","optimization"],"title":"Can we imitate Nature's evolutionary abilities? ","uri":"/genetic_algorithms/"},{"categories":["Genetic Algorithms"],"content":"Search for solutions In genetic algorithms, the search for a solution is carried on through an evolutionary process that begins with a collection of individuals, commonly referred to as a ‘population’. Each individual in this population is represented by its own unique chromosome, which is essentially an encoded set of attributes. Initially, this population is often generated randomly, representing a diverse range of potential solutions to the problem at hand. Members of one population are selected to create a new generation, guided by the aspiration that this new set of individuals will outperform the preceding ones. To achieve this aim, individuals are selected based on their ‘fitness’—a measure of their suitability for solving the given problem. The higher their fitness, the greater their chance of being chosen to produce offspring. To quantify this fitness, we employ a fitness function (also known as an evaluation function) that takes an individual as input and returns a scalar value. This numerical output enables us to compare the fitness levels of different individuals within the population. This evolutionary cycle continues until a certain condition is met, such as reaching a predetermined number of generations or achieving a sufficient improvement in the best solution. Procedure [Start] Generate a random population of n chromosomes (suitable solutions for the problem) [Fitness] Evaluate the fitness f(x) of each chromosome x in the population [New Population] Create a new population by repeating the following steps until the new population is complete: [Selection] Select two parent chromosomes from a population according to their fitness (the better the fitness, the bigger the chance to be selected). [Crossover] With a crossover probability, cross over the parents to form new offspring (children). If no crossover was performed, the offspring is an exact copy of the parents. [Mutation] With a mutation probability, mutate new offspring at each locus (position in chromosome). [Accepting] Place new offspring in the new population. [Replace] Use the new generated population for a further run of the algorithm. [Test] If the end condition is satisfied, stop, and return the best solution in the current population. [Loop] Go to step 2. ","date":"2023-10-01","objectID":"/genetic_algorithms/:1:3","tags":["evolutionary algorithms","heuristic search","machine learning","optimization"],"title":"Can we imitate Nature's evolutionary abilities? ","uri":"/genetic_algorithms/"},{"categories":["Genetic Algorithms"],"content":"Encoding of a Chromosome A chromosome encapsulates the information of the solution it represents. The most common form of encoding is a binary string. For instance: Chromosome 1: 1101100100110110 Chromosome 2: 1101111000011110 In this binary encoding, each bit could signify certain characteristics of the solution. Alternatively, the entire string could represent a numerical value, an approach often employed in basic GA implementations. However, encoding can vary depending on the problem at hand. For example, one could use integer or real numbers, or even encode permutations. ","date":"2023-10-01","objectID":"/genetic_algorithms/:1:4","tags":["evolutionary algorithms","heuristic search","machine learning","optimization"],"title":"Can we imitate Nature's evolutionary abilities? ","uri":"/genetic_algorithms/"},{"categories":["Genetic Algorithms"],"content":"Crossover Once the encoding method is chosen, the next step is the crossover operation. Crossover blends genes from parent chromosomes to produce new offspring. The simplest method involves picking a random crossover point and merging parts of the two parent chromosomes. Here’s a quick illustration (where | indicates the crossover point): Chromosome 1: 11011 | 00100110110 Chromosome 2: 11010 | 11000011110 Offspring 1: 11011 | 11000011110 Offspring 2: 11010 | 00100110110 Multiple crossover points can also be utilized, and the complexity of the crossover operation is often dictated by the type of encoding used. The crossover probability dictates the frequency of crossover operations. If crossover is bypassed, the offspring become exact replicas of their parents. On the other hand, if crossover is performed, the offspring inherit traits from both parents’ chromosomes. 100% Crossover Probability: All offspring are created through crossover. 0% Crossover Probability: The new generation is produced using exact copies of the chromosomes from the previous generation. Note that this doesn’t necessarily mean the new generation will be identical to the old one. The objective of crossover is to combine the advantageous traits from each parent, thereby generating improved offspring. However, it’s often beneficial to allow a portion of the older population to continue into the next generation. ","date":"2023-10-01","objectID":"/genetic_algorithms/:1:5","tags":["evolutionary algorithms","heuristic search","machine learning","optimization"],"title":"Can we imitate Nature's evolutionary abilities? ","uri":"/genetic_algorithms/"},{"categories":["Genetic Algorithms"],"content":"Mutation Following crossover, mutation comes into play. The purpose of mutation is to avoid convergence of the entire population to a local optimum. It involves making random changes to the offspring generated by the crossover. In the case of binary encoding, this could mean flipping random bits from 1 to 0 or vice versa. For example: Original Offspring 1: 1101111000011110 Original Offspring 2: 1101100100110110 Mutated Offspring 1: 1100111000011110 Mutated Offspring 2: 1101101100110110 Like crossover, the specific technique used for mutation largely depends on the chosen encoding method. For instance, if permutations are being encoded, mutation could be executed by swapping two genes. Mutation probability determines how frequently mutations will occur within a chromosome. In the absence of mutation, the offspring are produced either directly following crossover or as direct copies, with no changes applied. 100% Mutation Probability: The entire chromosome undergoes mutation. 0% Mutation Probability: No changes occur within the chromosome. Mutation serves as a mechanism to prevent the genetic algorithm from converging to local optima. However, excessive mutation is counterproductive, as the algorithm may essentially devolve into a random search. ","date":"2023-10-01","objectID":"/genetic_algorithms/:1:6","tags":["evolutionary algorithms","heuristic search","machine learning","optimization"],"title":"Can we imitate Nature's evolutionary abilities? ","uri":"/genetic_algorithms/"},{"categories":["Genetic Algorithms"],"content":"Selection As outlined early, chromosomes are selected from the population to serve as parents for the crossover operation. The challenge lies in deciding which chromosomes to select. Darwin’s theory of evolution suggests that the fittest individuals are more likely to survive and produce offspring. There are several methods for selecting these “fit” chromosomes, such as roulette wheel selection, Boltzmann selection, tournament selection, rank selection, steady-state selection, and others. This sections will describe some of these methods. Roulette Wheel Selection In this method, parents are selected based on their fitness levels. The fitter the chromosome, the higher the chance it has of being selected. Imagine a roulette wheel where each section is proportional to the fitness value of a chromosome. A marble is rolled on this wheel, and the chromosome where it stops is selected. Essentially, chromosomes with higher fitness values have larger sections and are more likely to be chosen. Here’s how the algorithm works: [Sum] Calculate the sum ( S ) of all chromosome fitnesses in the population. [Select] Generate a random number ( r ) from the interval ( (0, S) ). [Loop] Iterate through the population, summing fitnesses from 0 to ( s ). Stop and return the chromosome when ( s \u003e r ). Rank Selection Roulette wheel selection may become problematic when there are large disparities in fitness values. In such cases, rank selection can be more appropriate. In this method, chromosomes are first ranked. Each chromosome then receives a fitness score based on this ranking, from 1 (least fit) to ( N ) (most fit), where ( N ) is the number of chromosomes in the population. Steady-State Selection This isn’t a specific method of selecting parents, but rather an approach to population management. In this model, a large portion of the existing chromosomes can survive to the next generation. The basic idea is to select a few good chromosomes for creating new offspring, remove some less-fit chromosomes, and place the new offspring in their spots. Elitism Elitism is an approach where the best chromosome(s) are directly transferred to the next generation to ensure that the optimal solutions found so far are not lost. This can significantly improve the performance of a GA. ","date":"2023-10-01","objectID":"/genetic_algorithms/:1:7","tags":["evolutionary algorithms","heuristic search","machine learning","optimization"],"title":"Can we imitate Nature's evolutionary abilities? ","uri":"/genetic_algorithms/"},{"categories":["Genetic Algorithms"],"content":"Quick example of GA The following example aims to showcase the capabilities of genetic algorithms and provide a quick overview of the Distributed Evolutionary Algorithms in Python DEAP framework. DEAP is a Python library specifically designed for evolutionary computing. In this toy example, our objective is straightforward: we aim to find the minimum value of a function, which will be presented in the subsequent code cell, within the range [−33,33]. This example is adapted from the excellent ‘Neural Network’ seminar course offered at UTN-Paraná 2023, which is taught by the distinguished Dr.Matías Gerard. def F(x,y): ''' Función a optimizar. ''' z=-20.0*np.exp(-0.2*np.sqrt(0.5*(x**2+y**2)))-np.exp(0.5*(np.cos(2* np.pi*x)+np.cos(2*np.pi*y)))+np.e+20 return z This function gives the following output evaluated in the range [-33, 33]. As we can see, the function is simple and has a global minimum within the specified range, with no local minima. The evolutionary algorithm should solve it without difficulty. In order to solve this problem, we need a bunch of ingredients. First we have to define our individuals and to generate a population using them. Then we will add some functions and operators taking care of the evaluation and evolution of our population and finally put everything together in script. But first of all, we need to import some modules. import random !pip install deap from deap import base from deap import creator from deap import tools Then we will define some auxiliary functions: def bin(p=0.5): ''' Generate random bit ''' if random.random() \u003c p: return 1 else: return 0 def mutation(ind, p): ''' This function iterates through the chromosome and evaluates, for each gene, whether to apply the mutation operator. ''' return [abs(i-1) if random.random() \u003c p else i for i in ind] We implement the genotype-to-phenotype mapping function. We will represent the variables $x$ and $y$ using 12 and 24 bits, respectively. def bin2dec(ind, low, high, lengths): length_x, length_y = lengths ind_x = ind[:length_x] ind_y = ind[length_x:length_x+length_y] x = 0 for k,i in enumerate(ind_x[::-1]): x += (i * 2**k) x = low + ((high-low)/ (2**length_x - 1)) * x #Evolutionary Computation 1, p.169 and 2, p.39 y = 0 for k,i in enumerate(ind_y[::-1]): y += (i * 2**k) y = low + ((high-low)/ (2**length_y - 1)) * y return x, y Finally, we create a fitness function based on the objective function given above: def fitness(ind, low, high): ''' Fitness function for our problem ''' dec = bin2dec(ind, low=low, high=high, lengths=(12,24)) z = F(dec[0], dec[1]) return z Now let’s begin our evolutionary experiment. ","date":"2023-10-01","objectID":"/genetic_algorithms/:2:0","tags":["evolutionary algorithms","heuristic search","machine learning","optimization"],"title":"Can we imitate Nature's evolutionary abilities? ","uri":"/genetic_algorithms/"},{"categories":["Genetic Algorithms"],"content":"Set the parameters Before we go on, is time to define some constants we will use later on. IND_SIZE = 36 # cromosome LB = -33 # lower and upper bound UB = 33 POP_SIZE = 100 # populations PM = 1./IND_SIZE # probability of mutation N_PARENTS = POP_SIZE - 1 PX = 0.9 # probabiltiy of crossover GMAX = 100 ","date":"2023-10-01","objectID":"/genetic_algorithms/:2:1","tags":["evolutionary algorithms","heuristic search","machine learning","optimization"],"title":"Can we imitate Nature's evolutionary abilities? ","uri":"/genetic_algorithms/"},{"categories":["Genetic Algorithms"],"content":"Creator Since the actual structure of the required individuals in genetic algorithms does strongly depend on the task at hand, DEAP does not contain any explicit structure. It will rather provide a convenient method for creating containers of attributes, associated with fitnesses, called the deap.creator. Using this method we can create custom individuals in a very simple way. The creator is a class factory that can build new classes at run-time. It will be called with first the desired name of the new class, second the base class it will inherit, and in addition any subsequent arguments you want to become attributes of your class. This allows us to build new and complex structures of any type of container from lists to n-ary trees. creator.create(\"Fitness\", base.Fitness, weights=(-1.0,)) creator.create(\"Individual\", list, fitness=creator.Fitness) First we will define the class Fitness. It will inherit the Fitness class of the deap.base module and contain an additional attribute called weights. Please mind the value of weights to be the tuple (-1.0,), this way we will be minimizing a single objective fitness. In DEAP single objectives is a special case of multi-objectives. Next we will create the class Individual, which will inherit the class list and contain our previously defined Fitness class in its fitness attribute. Note that upon creation all our defined classes will be part of the creator container and can be called directly. ","date":"2023-10-01","objectID":"/genetic_algorithms/:2:2","tags":["evolutionary algorithms","heuristic search","machine learning","optimization"],"title":"Can we imitate Nature's evolutionary abilities? ","uri":"/genetic_algorithms/"},{"categories":["Genetic Algorithms"],"content":"Toolbox Now we will use our custom classes to create types representing our individuals as well as our whole population. All the objects we will use on our way, an individual, the population, as well as all functions, operators, and arguments will be stored in a DEAP container called Toolbox. It contains two methods for adding and removing content, register() and unregister(). toolbox = base.Toolbox() toolbox.register(\"attribute\", bin, p=0.5) toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attribute, n=IND_SIZE) toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual) In this code block we register a generation function toolbox.attribute() and two initialization ones individual() and population(). toolbox.attr_bool(), when called, will draw a random bits (0 or 1). The two initializers, on the other hand, will instantiate an individual or population. The registration of the tools to the toolbox only associates aliases to the already existing functions and freezes part of their arguments. This allows us to fix an arbitrary amount of argument at certain values so we only have to specify the remaining ones when calling the method. Our individuals will be generated using the function initRepeat(). Its first argument is a container class, in our example the Individual one we defined in the previous section. This container will be filled using the method attritubte(), provided as second argument, and will contain N bit, as specified using the third argument. When called, the individual() method will thus return an individual initialized with what would be returned by calling the attribute() method N times. Finally, the population() method uses the same paradigm, but we don’t fix the number of individuals that it should contain. ","date":"2023-10-01","objectID":"/genetic_algorithms/:2:3","tags":["evolutionary algorithms","heuristic search","machine learning","optimization"],"title":"Can we imitate Nature's evolutionary abilities? ","uri":"/genetic_algorithms/"},{"categories":["Genetic Algorithms"],"content":"The Evaluation Function The evaluation function in our example is given by the $F$ functions presented above. ","date":"2023-10-01","objectID":"/genetic_algorithms/:2:4","tags":["evolutionary algorithms","heuristic search","machine learning","optimization"],"title":"Can we imitate Nature's evolutionary abilities? ","uri":"/genetic_algorithms/"},{"categories":["Genetic Algorithms"],"content":"The Genetic Operators Within DEAP there are two ways of using operators. We can either simply call a function from the tools module or register it with its arguments in a toolbox, as we have already seen for our initialization methods. The most convenient way, however, is to register them in the toolbox, because this allows us to easily switch between the operators if desired. The toolbox method is also used when working with the algorithms module. Registering the genetic operators required for the evolution in our minimization problem and their default arguments in the toolbox is done as follows. toolbox.register(\"evaluate\", fitness) toolbox.register(\"mate\", tools.cxTwoPoint) toolbox.register(\"mutate\", mutation, p=PM) toolbox.register(\"select\", tools.selTournament, tournsize=5) The evaluation will be performed by calling the alias fitness. It is important to not fix its argument in here. We will need it later on to apply the function to each separate individual in our population. The mutation, on the other hand, needs an argument to be fixed (the independent probability of each attribute to be mutated). ","date":"2023-10-01","objectID":"/genetic_algorithms/:2:5","tags":["evolutionary algorithms","heuristic search","machine learning","optimization"],"title":"Can we imitate Nature's evolutionary abilities? ","uri":"/genetic_algorithms/"},{"categories":["Genetic Algorithms"],"content":"Evolving the Population Once the representation and the genetic operators are chosen, we will define an algorithm combining all the individual parts and performing the evolution of our population until the minimization problem is solved. ","date":"2023-10-01","objectID":"/genetic_algorithms/:2:6","tags":["evolutionary algorithms","heuristic search","machine learning","optimization"],"title":"Can we imitate Nature's evolutionary abilities? ","uri":"/genetic_algorithms/"},{"categories":["Genetic Algorithms"],"content":"Creating the Population First of all, we need to actually instantiate our population. But this step is effortlessly done using the population() method we registered in our toolbox earlier on. pop = toolbox.population(n=POP_SIZE) pop will be a list composed of 100 individuals. Since we left the parameter n open during the registration of the population() method in our toolbox, we are free to create populations of arbitrary size. ","date":"2023-10-01","objectID":"/genetic_algorithms/:2:7","tags":["evolutionary algorithms","heuristic search","machine learning","optimization"],"title":"Can we imitate Nature's evolutionary abilities? ","uri":"/genetic_algorithms/"},{"categories":["Genetic Algorithms"],"content":"Evaluating the Population The next thing to do is to evaluate our brand new population. We map() the evaluation function to every individual and then assign their respective fitness. Note that the order in fitnesses and population is the same. # Evaluate the entire population fitnesses = list(map(toolbox.evaluate, pop)) for ind, fit in zip(pop, fitnesses): ind.fitness.values = fit The evolution of the population is the final step we need to complete. Recall that our individuals are represented by 36-bit chromosomes, and our goal is to evolve the population until we reach the minimum of the objective function. To check the performance of the evolution, we will calculate some statistics in our population. # Fitness of individuals stats_fit = tools.Statistics(key=lambda ind: ind.fitness.values) # Lenght of individual stats_size = tools.Statistics(key=len) stats_active_genes = tools.Statistics(key=lambda ind: np.sum(ind)) mstats = tools.MultiStatistics(fitness=stats_fit, size=stats_size, genes=stats_active_genes) mstats.register(\"avg\", np.mean) mstats.register(\"std\", np.std) mstats.register(\"min\", np.min) mstats.register(\"max\", np.max) logbook = tools.Logbook() ","date":"2023-10-01","objectID":"/genetic_algorithms/:2:8","tags":["evolutionary algorithms","heuristic search","machine learning","optimization"],"title":"Can we imitate Nature's evolutionary abilities? ","uri":"/genetic_algorithms/"},{"categories":["Genetic Algorithms"],"content":"The Main Loop In genetic algorithms, evolution occurs via either mutation or crossover, both of which happen (or don’t happen) randomly. In mutation, we change one or more of the genes of one of our individuals. In cross-over, two individuals are mated to mix their genes. The crossover (or mating) and mutation operators, provided within DEAP, usually take respectively 2 or 1 individual(s) as input and return 2 or 1 modified individual(s). In addition they modify those individuals within the toolbox container and we do not need to reassign their results. We will perform both the crossover (mating) and the mutation of the produced children with a certain probability. The del statement will invalidate the fitness of the modified offspring. In the following script we will creates an offspring list, which is an exact copy of the selected individuals. The toolbox.clone() method ensure that we don’t use a reference to the individuals but an completely independent instance. This is of utter importance since the genetic operators in toolbox will modify the provided objects in-place. We then mutate and mate the individuals to find the next generation of individuals. We evaluate them, and continue until one of our individuals evolves to be the perfect organism (minimum), or until the number of generations reaches 100. At each generation, we output some statistics about that generation’s population and the best individual. records = mstats.compile(pop) logbook.record(gen=0, **records) for g in range(1,GMAX): idx_elite = np.argmin(fitnesses) elite = toolbox.clone(pop[idx_elite]) del elite.fitness.values parents = toolbox.select(pop, POP_SIZE) offspring = list(map(toolbox.clone, pop)) for i in range(POP_SIZE//2): parent1 = toolbox.clone(parents[random.randint(0,POP_SIZE-1)]) parent2 = toolbox.clone(parents[random.randint(0,POP_SIZE-1)]) if random.random() \u003c PX: childs = toolbox.mate(parent1, parent2) else: childs = (parent1, parent2) offspring[2*i] = childs[0] offspring[2*i+1] = childs[1] for mutant in offspring: toolbox.mutate(mutant) del mutant.fitness.values offspring[0] = elite fitnesses = Parallel(n_jobs=6, backend='multiprocessing')(delayed(fitness)(ind, LB, UB) for ind in offspring) for ind, fit in zip(offspring, fitnesses): ind.fitness.values = (fit,) pop = toolbox.clone(offspring) records = mstats.compile(pop) logbook.record(gen=g, **records) if (g%10 == 0): print('='*10) print(f'GENERATION: {g}') print(f'ELITE -- Fitness: {elite.fitness.values[0]:.4}') print('FITNES: ', records['fitness']) ","date":"2023-10-01","objectID":"/genetic_algorithms/:2:9","tags":["evolutionary algorithms","heuristic search","machine learning","optimization"],"title":"Can we imitate Nature's evolutionary abilities? ","uri":"/genetic_algorithms/"},{"categories":["Genetic Algorithms"],"content":"Evolution process: === GENERATION: 10 ELITE -- Fitness: 0.5722 FITNES: {'avg': 1.2363773729277125, 'std': 0.6934457474019109, 'min': 0.5671581279089928, 'max': 2.512008838665629} === GENERATION: 20 ELITE -- Fitness: 0.5671 FITNES: {'avg': 0.5670580268782999, 'std': 0.0, 'min': 0.5670580268782999, 'max': 0.5670580268782999} === GENERATION: 30 ELITE -- Fitness: 0.5671 FITNES: {'avg': 0.5670580268782999, 'std': 0.0, 'min': 0.5670580268782999, 'max': 0.5670580268782999} === GENERATION: 40 ELITE -- Fitness: 0.5671 FITNES: {'avg': 0.5670580268782999, 'std': 0.0, 'min': 0.5670580268782999, 'max': 0.5670580268782999} === GENERATION: 50 ELITE -- Fitness: 0.5671 FITNES: {'avg': 0.5670580268782999, 'std': 0.0, 'min': 0.5670580268782999, 'max': 0.5670580268782999} === GENERATION: 60 ELITE -- Fitness: 0.5671 FITNES: {'avg': 0.5670580268782999, 'std': 0.0, 'min': 0.5670580268782999, 'max': 0.5670580268782999} === GENERATION: 70 ELITE -- Fitness: 0.5671 FITNES: {'avg': 0.5670580268782999, 'std': 0.0, 'min': 0.5670580268782999, 'max': 0.5670580268782999} === GENERATION: 80 ELITE -- Fitness: 0.5671 FITNES: {'avg': 0.5670580268782999, 'std': 0.0, 'min': 0.5670580268782999, 'max': 0.5670580268782999} === GENERATION: 90 ELITE -- Fitness: 0.5671 FITNES: {'avg': 0.5670580268782999, 'std': 0.0, 'min': 0.5670580268782999, 'max': 0.5670580268782999} ","date":"2023-10-01","objectID":"/genetic_algorithms/:2:10","tags":["evolutionary algorithms","heuristic search","machine learning","optimization"],"title":"Can we imitate Nature's evolutionary abilities? ","uri":"/genetic_algorithms/"},{"categories":["Genetic Algorithms"],"content":"Solution ","date":"2023-10-01","objectID":"/genetic_algorithms/:2:11","tags":["evolutionary algorithms","heuristic search","machine learning","optimization"],"title":"Can we imitate Nature's evolutionary abilities? ","uri":"/genetic_algorithms/"},{"categories":["Genetic Algorithms"],"content":"Conclusion Genetic Algorithms showcase the robustness and versatility of bio-inspired computing. Their ability to explore complex, high-dimensional search spaces makes them invaluable in situations where traditional, exhaustive search methods fall short. Whether it’s optimization challenges in machine learning, route planning in logistics, or even simulating natural processes in biology, Genetic Algorithms have demonstrated their effectiveness across a diverse range of domains. While originally designed for the study of adaptation in natural systems (J. Holland, 1975), most GAs have been developed for optimization purposes (Whitley, 1994). They have been applied in a large variety of research domains: biology (Street and Mayo, 1999), economics (Chatterjee et al., 2018, Waheeb and Ghazali, 2019), finance (Lwin et al., 2014, Han et al., 2019), operational research (Della Croce et al., 1995, Baker and Ayechew, 2003), game theory (Axelrod et al., 1987, Vi ́e, 2020b), deep learning and neural networks (Stanley et al., 2019, Chung and Shin, 2020), forecasting (Packard, 1988, C. Ahn and Ramakrishna, 2003), optimisation (Wiransky, 2020, Dhunny et al., 2020), computer science and algorithms (Koza, 1992), healthcare (Tao et al., 2019, Devarriya et al., 2020) or data science (Yang and Honavar, 1998, Maulik and Bandyopadhyay, 2000, Raymer et al., 2000). As we continue to deepen our understanding of these algorithms, their range of applications is likely to expand, further cementing their status as a reliable tool for solving intricate problems. Bibliography Goldberg, David E. 1989. Genetic Algorithms in Search, Optimization, and Machine Learning. New York, NY, USA: Addison-Wesley. Kramer, Oliver. 2017. Genetic Algorithm Essentials. Vol. 679. Studies in Computational Intelligence. Cham: Springer International Publishing. Vignolo, Leandro D., and Matias F. Gerard. 2017. \"Evolutionary Local Improvement on Genetic Algorithms for Feature Selection.\" In 2017 XLIII Latin American Computer Conference (CLEI), 1–8. Cordoba: IEEE. https://doi.org/10.1109/CLEI.2017.8226467. Pics by mmmPIE in Reddit/HybridAnimals, and Dulcey Lima in Unsplash. ","date":"2023-10-01","objectID":"/genetic_algorithms/:3:0","tags":["evolutionary algorithms","heuristic search","machine learning","optimization"],"title":"Can we imitate Nature's evolutionary abilities? ","uri":"/genetic_algorithms/"},{"categories":["Generative Models"],"content":"Generative models are a class of statistical models that aim to learn the underlying data distribution from a given dataset. These models provide a way to generate new samples that are statistically similar to the training data. They have gained substantial attention in various domains, such as image generation, speech synthesis, and even drug discovery. ","date":"2023-09-01","objectID":"/variational_autoencoders/:0:0","tags":["expectation maximization","variational autoencoders","deep neural networks"],"title":"Generative Models: Variational Autoencoders","uri":"/variational_autoencoders/"},{"categories":["Generative Models"],"content":"Generative Model Generative models are a class of statistical models that aim to learn the underlying data distribution. Given a dataset of observed samples, one starts by selecting a distributional model parameterized by $(\\theta)$. The objective is to estimate $(\\theta)$ such that it aligns optimally with the observed samples.The anticipation is that it can also generalize to samples outside the training set. The optimal distribution is hence the one that maximizes the likelihood of producing the observed data, giving lower probabilities to infrequent observations and higher probabilities to the more common ones (the principle underlying this assumption is that ’the world is a boring place’ -in words of Bhiksha Raj-). ","date":"2023-09-01","objectID":"/variational_autoencoders/:1:0","tags":["expectation maximization","variational autoencoders","deep neural networks"],"title":"Generative Models: Variational Autoencoders","uri":"/variational_autoencoders/"},{"categories":["Generative Models"],"content":"The Challenge of Maximum Likelihood Estimates (MLE) for Unseen Observations When training generative models, a natural objective is to optimize the model parameters such that the likelihood of the observed data under the model is maximized. This method is known as Maximum Likelihood Estimation (MLE). In mathematical terms, given observed data $X$, the MLE seeks parameters $\\theta$ that maximize: $$p_\\theta(X)$$ However, for many generative models, especially those that involve latent or unobserved variables, the likelihood term involves summing or integrating over all possible configurations of these latent variables. Mathematically, this turns into: $$p_\\theta(X) = \\sum_{Z} p_\\theta(X,Z)$$ $$or$$ $$p_\\theta(X) = \\int p_\\theta(X,Z) dZ$$ Computing the log-likelihood, which is often used for numerical stability and optimization ease, leads to a log of summations (for discrete latent variables) or a log of integrals (for continuous latent variables): $$log p_\\theta(X) = \\log \\sum_{Z} p_\\theta(X,Z)$$ $$or$$ $$log p_\\theta(X) = \\log \\int p_\\theta(X,Z) dZ$$ These expressions are typically intractable to optimize directly due to the presence of the log-sum or log-integral operations (see the info below). Marginalization in Joint Probability ","date":"2023-09-01","objectID":"/variational_autoencoders/:2:0","tags":["expectation maximization","variational autoencoders","deep neural networks"],"title":"Generative Models: Variational Autoencoders","uri":"/variational_autoencoders/"},{"categories":["Generative Models"],"content":"Marginalization in the Context of Joint Probability When discussing the computation of the joint probability for observed and missing data, the term “marginalizing” refers to summing or integrating over all possible outcomes of the missing data. This process provides a probability distribution based solely on the observed data. For example, let’s assume: $X$ is the observed data $Z$ is the missing data The joint probability for both is represented as $p(X,Z)$ If your primary interest lies in the distribution of $X$ and you wish to eliminate the dependence on $Z$, you’ll need to carry out marginalization for $Z$. For discrete variables, the marginalization involves the logarithm of summation, and for continuous variables, it pertains to integration. In any case, functions that includes the log of a sum o integral defies direct optimization. Can we get an approximation to this that is more tractable (without a summation or integral within the log)? ","date":"2023-09-01","objectID":"/variational_autoencoders/:3:0","tags":["expectation maximization","variational autoencoders","deep neural networks"],"title":"Generative Models: Variational Autoencoders","uri":"/variational_autoencoders/"},{"categories":["Generative Models"],"content":"Overcoming the Challenge with Expectation Maximization (EM) To address the optimization challenge in MLE with latent variables, the Expectation Maximization (EM) algorithm is employed. The EM algorithm offers a systematic approach to iteratively estimate both the model parameters and the latent variables. The algorithm involves two main steps: E-step (Expectation step): involves computing the expected value of the complete-data log-likelihood with respect to the posterior distribution of the latent variables given the observed data. M-step (Maximization step): Update the model parameters to maximize this expected log-likelihood from the E-step. By alternating between these two steps, EM ensures that the likelihood increases with each iteration until convergence, thus providing a practical method to fit generative models with latent variables. For E-step the Variational Lower Bound is used. Commonly referred to as the Empirical Lower BOund (ELBO), is a central concept in variational inference. This method is used to approximate complex distributions (typically posterior distributions) with simpler, more tractable ones. The ELBO is an auxiliary function that provides a lower bound to the log likelihood of the observed data. By iteratively maximizing the ELBO with respect to variational parameters, we approximate the Maximum Likelihood Estimation (MLE) of the model parameters. Let’s reconsider our aim to maximize the log-likelihood of observations $x$ in terms of $q_\\phi(z|x)$. $$\\log p_\\theta(x) = \\log \\int z p_\\theta(x,z)dz$$ $$ = \\log \\int z \\frac{p_\\theta(x,z)q_\\phi(z|x)}{q_\\phi(z|x)}dz$$ $$= \\log E_{z \\sim q_\\phi(z|x)} \\left[ \\frac{p_\\theta(x,z)}{q_\\phi(z|x)} \\right]$$ $$\\geq E_z \\left[ \\log \\frac{p_\\theta(x,z)}{q_\\phi(z|x)} \\right] \\quad \\text{(by Jensen’s inequality)}$$ $$= E_z[\\log p_\\theta(x,z)] + \\int z q_\\phi(z|x) \\log \\frac{1}{q_\\phi(z|x)} dz$$ $$= E_z[\\log p_\\theta(x,z)] + H(q_\\phi(z|x))$$ In the equation above, the term $H(\\cdot)$ denotes the Shannon entropy. By definition, the term “evidence” is the value of a likelihood function evaluated with fixed parameters. With the definition of: $$L = E_z[\\log p_\\theta(x,z)] + H(q_\\phi(z|x)),$$ it turns out that $L$ sets a lower bound for the evidence of observations and maximizes $L$ will push up the log-likelihood of $x$. ","date":"2023-09-01","objectID":"/variational_autoencoders/:4:0","tags":["expectation maximization","variational autoencoders","deep neural networks"],"title":"Generative Models: Variational Autoencoders","uri":"/variational_autoencoders/"},{"categories":["Generative Models"],"content":"Variational Autoencoders (VAEs) Variational Autoencoders are a specific type of generative model that brings together ideas from deep learning and Bayesian inference. VAEs are especially known for their application in generating new, similar data to the input data (like images or texts) and for their ability to learn latent representations of data. 1. Generative Models and Latent Variables In generative modeling, our goal is to learn a model of the probability distribution from which a dataset is drawn. The model can then be used to generate new samples. A VAE makes a specific assumption that there exist some latent variables (or hidden variables) that when transformed give rise to the observed data. Let $x$ be the observed data and $z$ be the latent variables. The generative story can be seen as: Draw $z$ from a prior distribution, $p(z)$. Draw $x$ from a conditional distribution, $p(x|z)$. 2. Problem of Direct Inference As discussed previously, direct inference for the posterior distribution $p(z|x)$ (i.e., the probability of the latent variables given the observed data) can be computationally challenging, especially when dealing with high-dimensional data or complex models. This is because: $$ p(z|x) = \\frac{p(x|z) p(z)}{p(x)} $$ Here, $p(x)$ is the evidence (or marginal likelihood) which is calculated as: $$ p(x) = \\int p(x|z) p(z) dz $$ As we saw this integral is intractable for most interesting models. 3. Variational Inference and ELBO To sidestep the intractability of the posterior, VAEs employ variational inference. Instead of computing the posterior directly, we introduce a parametric approximate posterior distribution, $q_{\\phi}(z|x)$, with its own parameters $\\phi$. The goal now shifts to making this approximation as close as possible to the true posterior. This is done by minimizing the Kullback-Leibler divergence between the approximate and true posterior using the ELBO function. 4. Neural Networks and Autoencoding Structure In VAEs, neural networks are employed to parameterize the complex functions. Specifically: Encoder Network: This maps the observed data, $x$, to the parameters of the approximate posterior, $q_{\\phi}(z|x)$. Decoder Network: Given samples of $z$ drawn from $q_{\\phi}(z|x)$, this maps back to the data space, outputting parameters for the data likelihood, $p_{\\theta}(x|z)$. The “autoencoder” terminology comes from the encoder-decoder structure where the model is trained to reconstruct its input data. 5. Training a VAE The training process involves: Forward pass: Input data is passed through the encoder to obtain parameters of $q_{\\phi}(z|x)$. Sampling: Latent variables $z$ are sampled from $q_{\\phi}(z|x)$ using the reparameterization trick for backpropagation. Reconstruction: The sampled $z$ values are passed through the decoder to obtain the data likelihood parameters, $p_{\\theta}(x|z)$. Loss Computation: Two terms are considered - reconstruction loss (how well the VAE reconstructs the data) and the KL divergence between $q_{\\phi}(z|x)$ and $p(z)$. Backpropagation and Optimization: The model parameters $\\phi$ and $\\theta$ are updated to maximize the ELBO. By the end of the training, you’ll have a model that can generate new samples resembling your input data by simply sampling from the latent space and decoding the samples. VAEs are a powerful tools, that stay in the intersection of deep learning and probabilistic modeling, and they have a plethora of applications, especially in unsupervised learning tasks. ","date":"2023-09-01","objectID":"/variational_autoencoders/:5:0","tags":["expectation maximization","variational autoencoders","deep neural networks"],"title":"Generative Models: Variational Autoencoders","uri":"/variational_autoencoders/"},{"categories":["Generative Models"],"content":"Variational Encoders with Pytorch Let create a basic implementation of a Variational Autoencoder (VAE) using PyTorch. The VAE will be designed to work on simple image data, such as the MNIST dataset. import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim import torchvision from torchvision import datasets, transforms # Define the VAE architecture class VAE(nn.Module): def __init__(self, input_dim, hidden_dim, latent_dim): super(VAE, self).__init__() # Encoder self.fc1 = nn.Linear(input_dim, hidden_dim) self.fc21 = nn.Linear(hidden_dim, latent_dim) # mu self.fc22 = nn.Linear(hidden_dim, latent_dim) # logvar # Decoder self.fc3 = nn.Linear(latent_dim, hidden_dim) self.fc4 = nn.Linear(hidden_dim, input_dim) self.latent_dim = latent_dim # Add this line def encode(self, x): h1 = F.relu(self.fc1(x)) return self.fc21(h1), self.fc22(h1) def reparameterize(self, mu, logvar): std = torch.exp(0.5*logvar) eps = torch.randn_like(std) return mu + eps*std def decode(self, z): h3 = F.relu(self.fc3(z)) return torch.sigmoid(self.fc4(h3)) def forward(self, x): mu, logvar = self.encode(x.view(-1, 784)) z = self.reparameterize(mu, logvar) return self.decode(z), mu, logvar # Loss function: Reconstruction + KL Divergence Losses summed over all elements and batch def loss_function(recon_x, x, mu, logvar): BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum') # KLD = -0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2) KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) return BCE + KLD def train(epoch): model.train() train_loss = 0 for batch_idx, (data, _) in enumerate(train_loader): optimizer.zero_grad() recon_batch, mu, logvar = model(data) loss = loss_function(recon_batch, data, mu, logvar) loss.backward() train_loss += loss.item() optimizer.step() if batch_idx % 100 == 0: print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format( epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item() / len(data))) print('====\u003e Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset))) def test(): model.eval() test_loss = 0 with torch.no_grad(): for i, (data, _) in enumerate(test_loader): recon_batch, mu, logvar = model(data) test_loss += loss_function(recon_batch, data, mu, logvar).item() if i == 0: n = min(data.size(0), 8) comparison = torch.cat([data[:n], recon_batch.view(batch_size, 1, 28, 28)[:n]]) torchvision.utils.save_image(comparison.cpu(), 'reconstruction_' + str(epoch) + '.png', nrow=n) test_loss /= len(test_loader.dataset) print('====\u003e Test set loss: {:.4f}'.format(test_loss)) transform = transforms.Compose([transforms.ToTensor()]) train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True) test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True) batch_size = 128 train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True) test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False) model = VAE(input_dim=784, hidden_dim=400, latent_dim=20) optimizer = optim.Adam(model.parameters(), lr=1e-3) # Run the training loop epochs = 10 for epoch in range(1, epochs + 1): train(epoch) test() Train Epoch: 1 [0/60000 (0%)] Loss: 547.095459 Train Epoch: 1 [12800/60000 (21%)] Loss: 177.320297 Train Epoch: 1 [25600/60000 (43%)] Loss: 156.426804 Train Epoch: 1 [38400/60000 (64%)] Loss: 137.500916 Train Epoch: 1 [51200/60000 (85%)] Loss: 130.676682 ====\u003e Epoch: 1 Average loss: 164.3802 ====\u003e Test set loss: 127.3049 Train Epoch: 2 [0/60000 (0%)] Loss: 129.183395 Train Epoch: 2 [12800/60000 (21%)] Loss: 124.367867 Train Epoch: 2 [25600/60000 (43%)] Loss: 119.659966 Train Epoch: 2 [38400/60000 (64%)] Loss: 120.912560 Train Epoch: 2 [51200/60000 (85%)] Loss: 114.011864 ====\u003e Epoch: 2 Average loss: 121.6398 ====\u003e Test set loss: 115.7936 Train Epoch: 3 [0/60000 (0%)] Loss: 114.913048","date":"2023-09-01","objectID":"/variational_autoencoders/:6:0","tags":["expectation maximization","variational autoencoders","deep neural networks"],"title":"Generative Models: Variational Autoencoders","uri":"/variational_autoencoders/"},{"categories":["Generative Models"],"content":"Bibliography Doersch, Carl. 2021. “Tutorial on Variational Autoencoders.” January 3, 2021. http://arxiv.org/abs/1606.05908. Kingma, Diederik P., and Max Welling. 2019. “An Introduction to Variational Autoencoders.” Foundations and Trends® in Machine Learning 12 (4): 307–92. https://doi.org/10.1561/2200000056. Ramchandran, Siddharth, Gleb Tikhonov, Otto Lönnroth, Pekka Tiikkainen, and Harri Lähdesmäki. 2022. “Learning Conditional Variational Autoencoders with Missing Covariates.” March 2, 2022. http://arxiv.org/abs/2203.01218. Yunfan Jiang, ELBO — What \u0026 Why,Jan 11, 2021, in https://yunfanj.com/blog/2021/01/11/ELBO.html. Pic by @vecstock, Freepik ","date":"2023-09-01","objectID":"/variational_autoencoders/:7:0","tags":["expectation maximization","variational autoencoders","deep neural networks"],"title":"Generative Models: Variational Autoencoders","uri":"/variational_autoencoders/"},{"categories":["Chatbot+"],"content":"I developed a chatbot-like agent that utilizes Retrieval-Augmented Generation, integrating a pre-trained sequence-to-sequence model with a document database. This innovative synergy facilitates the creation of a question-answering application, which is capable of delivering contextually relevant and accurate responses by querying specific information. ","date":"2023-09-01","objectID":"/documents_qa/:0:0","tags":["chatbot","llm","question-answering"],"title":"Retrieval-augmented generation for Chatbot","uri":"/documents_qa/"},{"categories":["Chatbot+"],"content":"Chatbot and Data Base In the advanced domain of Natural Language Processing (NLP), large pre-trained language models have become pivotal tools, showcasing superior performance in embedding factual knowledge and achieving state-of-the-art outcomes on various downstream tasks. However, these models exhibit constraints, particularly in their ability to accurately access and manipulate knowledge. Such limitations become evident in knowledge-intensive tasks, where their efficacy can be surpassed by specialized architectures. In this context, I constructed a prototype to explore this technology. My goal was to integrate the capabilities of pre-trained parametric memory with the expansive nature of non-parametric one. Thus, I developed a chatbot with access to a knowledge base. Utilizing retrieval-augmented generation, this system incorporates a pre-trained seq2seq model as its parametric memory and a dense vector index of documents as its non-parametric counterpart. ","date":"2023-09-01","objectID":"/documents_qa/:1:0","tags":["chatbot","llm","question-answering"],"title":"Retrieval-augmented generation for Chatbot","uri":"/documents_qa/"},{"categories":["Chatbot+"],"content":"Dataset Overview The chosen dataset come from the VAST 2014 Challenge The Kronos Incident. The 2014 IEEE Visual Analytics Science and Technology (VAST) Challenge researchers with a fictional scenario: the disappearance of staff members from the GASTech oil and gas company on Kronos Island. The dataset comprises: Geospatial Data: Geographic coordinates, maps, event locations, trajectories of vehicles or individuals. Temporal Data: Time series, timestamps, chronological events. Network Data: Information on connections between entities, such as phone calls, social media interactions, data traffic flows. Textual Data: Information in text form, like emails, chat logs, incident reports, etc. Numerical Data: Numeric values that might be related to the incident, such as counts, measurements, quantities. A total of 845 emails, 39 Word documents, 2 Excel sheets, and 1 CSV text file were processed to construct a vector database comprising 887 documents. ","date":"2023-09-01","objectID":"/documents_qa/:2:0","tags":["chatbot","llm","question-answering"],"title":"Retrieval-augmented generation for Chatbot","uri":"/documents_qa/"},{"categories":["Chatbot+"],"content":"Solution’s Architecture The project is challenging as it proposes the construction of a complex system, comprised of two textual data processing modules, each with its respective language models. The final system outcome is conditioned by the performance of both modules individually and their correct integration. Several experiments were conducted, adjusting the model composition and also switching the computing architecture from CPU to GPU. Two system versions were built, with a third variation for GPU processing. Architecture Overview The architecture consists of two major components: 1. Searcher Its primary goal is to find fragments of text within the corpus that can be used to answer the user-generated question. For our searcher module, we utilized all-MiniLM-L6-v2, developed by Google AI. This language model, based on transformers, has 137 billion parameters and is an enhanced version of the MiniLM-L6 model. It’s smaller and lighter than the BERT model. It’s trained on a massive dataset that includes books, articles, code, and other forms of text. 2. Generator Focused on text construction.The generation module is built using Llama 2, developed by Meta AI. This LLM (Language Learning Model) is a pre-trained transformer model that can be used for various tasks, including translation, summarization, crafting different types of creative content, and informatively answering questions. Due to the model’s size, we used a quantized version of Llama 2 for our application. Quantization is the technique that reduces the number of bits used to represent a number or value. In the context of LLMs, this means decreasing the precision of the model’s parameters by storing the weights in lower precision data types. Specifically, the original values, encoded in 16 bits, were converted to 8 bits. Question-Answering Solution Process Step Description Details 1. Input Receive Question The system starts by receiving a question, denoted as 'p'. 2. Vectorization Convert Question to Vector The question 'p' is transformed into its vectorized form. 3. Document Search Match Question with Documents The vectorized question is compared against the documents in the corpus 'C' to find potential matches. 4. Identify Relevant Documents Select Documents `[d1,d2]`` Based on the similarity scores, the system identifies the most relevant documents from the corpus that might contain the answer. 5. Generate Answer Provide Response The system generates an answer based on the content of the most similar documents. The solution addresses the Question-Answering problem in two steps. It first operates on a vectorized database of our corpus C, where each 500-character document has its associated embedding. The search is performed based on similarity between the vectorized question p and the corpus documents [d1,...,dN] using their respective indices. For similarity calculation, we use the Euclidean distance between vectors with the L2 norm (vector subtraction, where the resulting vector’s L2 norm gives us the distance between them: the smaller the distance, the greater the similarity). Embeddings ","date":"2023-09-01","objectID":"/documents_qa/:3:0","tags":["chatbot","llm","question-answering"],"title":"Retrieval-augmented generation for Chatbot","uri":"/documents_qa/"},{"categories":["Chatbot+"],"content":"Embeddings Embeddings are a type of word representation that captures the semantic meaning of words based on their context in a high-dimensional space. They are vectors of real numbers where words with similar meanings have similar embeddings. The idea is to represent words in a dense vector space where the position of each word is learned from its context in a large dataset. One of the most popular methods to generate embeddings is through neural networks, such as Word2Vec, GloVe, and FastText. Mathematically, an embedding for a word $w$ can be represented as: $$e(w) = [e_1, e_2, …, e_n]$$ Where: $e(w)$ is the embedding of the word $w$. $e_1, e_2, …, e_n$ are the components of the embedding in the $n$-dimensional space. ","date":"2023-09-01","objectID":"/documents_qa/:3:1","tags":["chatbot","llm","question-answering"],"title":"Retrieval-augmented generation for Chatbot","uri":"/documents_qa/"},{"categories":["Chatbot+"],"content":"Euclidean Distance for Similarity Search Euclidean distance is a measure of the straight-line distance between two points in Euclidean space. It’s commonly used to measure the similarity between vectors, such as embeddings. The idea is that the closer two vectors are in this space, the more similar they are. Given two points $P$ and $Q$ with coordinates $(p_1, p_2, …, p_n)$ and $(q_1, q_2, …, q_n)$ respectively in an $n$-dimensional space, the Euclidean distance $d$ between them is given by: $$d(P, Q) = \\sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2 + … + (p_n - q_n)^2}$$ In the context of similarity search, smaller Euclidean distances indicate higher similarity. When using embeddings for similarity search, the embeddings of two words or documents are compared using the Euclidean distance to determine how semantically similar they are. After this stage, we proceed to a second step which involves generating an answer r conditioned on the retrieved information. The generation takes the question p and the 2 most similar documents (smallest distance), combines them into a single question-context (prompt) document, and passes it to a language generation model to formulate the answer r. In this final step, we are using Llama2 with 7 billion parameters, optimized for Question-Answering (chat). Large Language Models ","date":"2023-09-01","objectID":"/documents_qa/:3:2","tags":["chatbot","llm","question-answering"],"title":"Retrieval-augmented generation for Chatbot","uri":"/documents_qa/"},{"categories":["Chatbot+"],"content":"Large Language Models (LLMs) Large Language Models (LLMs) are a type of deep learning model designed to understand and generate human-like text. They are trained on vast amounts of text data and have the capacity to generate coherent and contextually relevant sentences over long passages. The “large” in LLMs refers to the number of parameters these models have, often ranging from hundreds of millions to tens of billions. Mathematically, an LLM can be represented as a function $f$ that maps an input sequence of tokens $x_1, x_2, …, x_n$ to an output sequence of tokens $y_1, y_2, …, y_m$: $$f: (x_1, x_2, …, x_n) \\rightarrow (y_1, y_2, …, y_m)$$ Where: $(x_1, x_2, …, x_n)$ is the input sequence. $(y_1, y_2, …, y_m)$ is the output sequence. $f$ is the function representing the LLM. ","date":"2023-09-01","objectID":"/documents_qa/:3:3","tags":["chatbot","llm","question-answering"],"title":"Retrieval-augmented generation for Chatbot","uri":"/documents_qa/"},{"categories":["Chatbot+"],"content":"Llama 2 Llama 2 is an advanced iteration of Large Language Models developed with a focus on chat and dialogue use cases. It consists of a collection of pretrained and fine-tuned LLMs ranging in scale from 7 billion to 70 billion parameters. The fine-tuned versions, known as Llama 2-Chat, are specifically optimized for dialogue scenarios. Key features of Llama 2 include: Scale: Models range from 7 billion to 70 billion parameters, allowing for a wide variety of applications and use cases. Performance: Llama 2 models outperform many open-source chat models on several benchmarks. Fine-tuning: Llama 2-Chat models are fine-tuned to be optimized for dialogue use cases, ensuring coherent and contextually relevant responses in conversational scenarios. Safety: Significant efforts have been made to ensure that Llama 2-Chat models are safe and provide helpful responses. This is based on human evaluations for helpfulness and safety. Open Development: A detailed description of the approach to fine-tuning and safety improvements of Llama 2-Chat is provided, enabling the community to build upon and contribute to the responsible development of LLMs. In essence, Llama 2 represents a significant step forward in the development of LLMs, especially for chat and dialogue applications. The emphasis on safety and the detailed documentation provided aim to ensure that the community can use and further develop these models responsibly. More details in: https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/ A primary challenge in implementing the described solution on a personal-type CPU (4 processors and 12GB of RAM) is the size of the models. For this reason, in Version 1 of our solution, we worked with the following specifications: for embedding operations (on C and p) we used the all-MiniLM-L6-v2 model that produces a dense 384-dimensional vector space. For the r answer generation operation, we worked with a quantized version of Llama 2, 7b, 8-bit (an exploratory attempt was made with the 13 billion parameter model, thwarted by lack of RAM). Similarity operations are performed using the FAISS library for efficient similarity search among dense vectors. ","date":"2023-09-01","objectID":"/documents_qa/:3:4","tags":["chatbot","llm","question-answering"],"title":"Retrieval-augmented generation for Chatbot","uri":"/documents_qa/"},{"categories":["Chatbot+"],"content":"Evaluation To evaluate our model, several Question-Answering experiments were conducted, taking the answers provided as a solution to the Vast-Challenge competition as the ground truth. That is, we compared the answers formulated by analysts who participated in the competition with the answers provided by our solution. For this comparison, we used cosine distance. ","date":"2023-09-01","objectID":"/documents_qa/:4:0","tags":["chatbot","llm","question-answering"],"title":"Retrieval-augmented generation for Chatbot","uri":"/documents_qa/"},{"categories":["Chatbot+"],"content":"Experiments: CPU Version 1 provides unsatisfactory results not only due to the answer content but also due to system latency, caused by the prolonged generation process. For example, we have this question-answer: Question ‘What is the name of the young girl who dies and what are the causes of the death?’ Analyst’s Answer ‘The name of the girl who died is Juliana Vann. The cause of death is a lingering illness, which WFA-funded doctors claimed was caused by water contamination.’ Our Model’s Answer ‘The name of the young girl who died is Elodis. The cause of death is leukemia due to benzene poisoning.’ Cosine Similarity 0.5957 We see that the model fails to identify the girl, offering an answer with a similarity score of 0.59. This difficulty is associated with the retrieval module, particularly the document vectorization model. This is because, although the documents identified as similar to the question contained relevant information, they had a marginal treatment of the question’s subject. Therefore, the failure in the generator model is strongly conditioned by the context that served as input. In addition to the above, the delay in formulating the answer was 272 seconds, which is unfeasible for a solution like ours. Given these difficulties, we implemented a Version 2 of the solution with the following transformations. We replaced the all-MiniLM-L6-v2 model with the gte-base, which scored higher on the Overall MTEB English leaderboard. With this, we not only sought to improve the representation of the documents to favor the search but also the transformation of the question for similarity analysis. Several adjustments were made to the solution architecture to improve execution time, considering that 0.62% of the delay is in the generation module. With these transformations, we obtained the following results: Question ‘What is the name of the young girl who dies and what are the causes of the death?’ Analyst’s Answer ‘The name of the girl who died is Juliana Vann. The cause of death is a lingering illness, which WFA-funded doctors claimed was caused by water contamination.’ Our Model’s Answer ‘The name of the young girl who died is Juliana Vann, and the cause of her death is a lingering illness caused by water contamination according to WFA-funded doctors.’ Cosine Similarity 0.9747 The improvement in the answer content was accompanied by a reduction in system latency, which lasted 163 seconds (+- 20). A series of experiments were conducted with questions that implied extractive and generative answers, with promising results in both cases. Therefore, we took a further step, reconfiguring the entire architecture to run in a GPU environment. ","date":"2023-09-01","objectID":"/documents_qa/:5:0","tags":["chatbot","llm","question-answering"],"title":"Retrieval-augmented generation for Chatbot","uri":"/documents_qa/"},{"categories":["Chatbot+"],"content":"Experiments: GPU Version 3 of the solution was readapted to run in a higher capacity environment on Google Colab, which implied significant changes. Although we kept the language models selected in Version 2, all processing performed in both modules was adjusted to run on GPU. Even the similarity calculation between the question and the database runs on GPU. To evaluate this third version, we conducted 10 question-answer experiments. Regarding the question presented above, we obtained - as expected - the same answer obtained in Version 2 but with a latency reduction of -40 seconds. This is a positive result. In another satisfactorily resolved question, we have these results: Question ‘Where does the core of the kidnapping activities take place?’ Analyst’s Answer ‘The kidnapping takes place at GASTech Headquarters in the southern part of Abila, Kronos.’ Our Model’s Answer ‘The core of the kidnapping activities takes place in the city of Kronos.’ Cosine Similarity 0.7201 More complex questions generally yielded unsatisfactory results. For example, in the following case, we formulated a question that assumes a significant level of synthesis and abstraction of the corpus documents that the model fails to resolve. Question ‘What were the motivations behind the kidnapping carried out by the more violent wing of the POK?’ Analyst’s Answer ‘The more violent wing of the POK under the leadership of Mandor Vann (uncle to Isia and Juliana Vann) were motivated to kidnap members of GASTech’s leadership to exact revenge for years of pollution that GASTech’s drilling operations have inflicted on the people of Elodis. Additional motivations include GASTech’s recent IPO which resulted in massive payouts for GASTech leadership, making them ripe for ransom. Another motivation for the kidnapping is the frustration with the corruption and lax environmental regulation of the Government of Kronos, personified by GASTech.’ Our Model’s Answer ‘The motivations behind the kidnapping carried out by the more violent wing of the POK are likely rooted in their anarchist ideology and a desire to create chaos and undermine the authority of the state. They may see this act as a way to further their goals of overthrowing the government and establishing a new society free from oppressive structures.’ Cosine Similarity 0.5404 The model captures a general idea of the topic but does not articulate an appropriate answer. It fails to identify motives, circumstances, and people. It suffers from a systematic phenomenon in generative models related to ‘hallucination’. LLM`s challenges ","date":"2023-09-01","objectID":"/documents_qa/:6:0","tags":["chatbot","llm","question-answering"],"title":"Retrieval-augmented generation for Chatbot","uri":"/documents_qa/"},{"categories":["Chatbot+"],"content":"Problems with Large Language Models (LLMs) While Large Language Models (LLMs) have shown remarkable capabilities in understanding and generating human-like text, they are not without their challenges. One of the notable problems faced by LLMs is the phenomenon known as “hallucination.” ","date":"2023-09-01","objectID":"/documents_qa/:6:1","tags":["chatbot","llm","question-answering"],"title":"Retrieval-augmented generation for Chatbot","uri":"/documents_qa/"},{"categories":["Chatbot+"],"content":"Hallucination in LLMs Hallucination refers to the generation of information by the model that is not present or supported by the input data. In other words, the model “makes up” details or facts that are not grounded in reality or the provided context. Causes: Training Data: LLMs are trained on vast amounts of data, and they might have encountered conflicting or incorrect information during training. This can lead them to generate outputs that are not always accurate. Model Complexity: The sheer number of parameters in LLMs can sometimes lead to overfitting, where the model might generate outputs based on patterns it “thinks” it has learned, even if they aren’t valid. Lack of Ground Truth: Unlike supervised learning where there’s a clear ground truth, LLMs often operate in settings where the “correct” output is ambiguous, leading to potential hallucinations. Implications: Misinformation: Hallucination can lead to the spread of false or misleading information, especially if users trust the model’s outputs without verification. Reliability: For critical applications, hallucinations can undermine the reliability of the model, making it unsuitable for tasks that require high precision. Solutions: Fine-tuning: Fine-tuning the model on a narrower, domain-specific dataset can help reduce hallucinations by making the model more specialized. Prompt Engineering: Designing prompts carefully can guide the model to produce more accurate and less hallucinatory outputs. Model Interpretability: Developing tools and techniques to understand why a model is producing a particular output can help in identifying and mitigating hallucinations. In conclusion, while LLMs offer significant advancements in natural language processing, it’s essential to be aware of their limitations, such as hallucination. Proper understanding, fine-tuning, and continuous monitoring are crucial to harnessing their potential responsibly. However, the reason for the failure is not attributable to the results of the modules considered individually but to the solution in general. In effect, if we analyze the elements of this third experiment, we will find that the answer has a pertinent relationship with the available information, i.e., ‘question + context -\u003e answer’ are acceptable, although the final result does not relate to the truth as formulated by analysts. This is because: a) the retrieval module only takes 2 documents as relevant context information due to a model limit, leaving with partial information, b) this partial information is strongly conditioned by the bias that the information has, which translates into a text with categorical and polarizing terms, and c) the decontextualization that needs to be performed for the generation instance lacks a weighting or rebalancing strategy of the corpus’s structuring semantic contents and therefore reproduces a partial and decontextualized idea of its information. A significant number of conducted experiments show critical solution failures. They particularly point to poor performance of the retrieval module. In these cases, the model responds that it ‘does not have information to answer the question (‘I don’t know…’). That is, the modules conflict, arriving at an unacceptable result. Question ‘‘On what date do the microblog collection days occur’?’ Analyst’s Answer ‘January 23, 2014. The microblog collection days that include (at least) three major events related to the scenario.’ Our Model’s Answer ‘I don’t know the answer to that question, I’m just an AI and do not have access to the specific information you are seeking.’ Finally, other experiments failed because they arrived at answers that deviate from the truth. In these cases, a failure in the retrieval module can also be observed. ","date":"2023-09-01","objectID":"/documents_qa/:6:2","tags":["chatbot","llm","question-answering"],"title":"Retrieval-augmented generation for Chatbot","uri":"/documents_qa/"},{"categories":["Chatbot+"],"content":"Python, LLama2 and HuggingFace import box import timeit import yaml import argparse from dotenv import find_dotenv, load_dotenv from src.utils import setup_dbqa import torch from langchain.embeddings import HuggingFaceEmbeddings # Load environment variables from .env file load_dotenv(find_dotenv()) gpu = torch.cuda.is_available() # Import config vars with open('config/config.yml', 'r', encoding='utf8') as ymlfile: cfg = box.Box(yaml.safe_load(ymlfile)) if gpu: embeddings = HuggingFaceEmbeddings(model_name=\"thenlper/gte-base\", model_kwargs={'device': 'cuda'}) else: embeddings = HuggingFaceEmbeddings(model_name=\"thenlper/gte-base\", model_kwargs={'device': 'cpu'}) if __name__ == \"__main__\": parser = argparse.ArgumentParser() parser.add_argument('input', type=str, default='What were the motivations behind the kidnapping carried out by the more violent wing of the POK?', help='Enter the query to pass into the LLM') args = parser.parse_args() # Setup DBQA start = timeit.default_timer() dbqa = setup_dbqa(embeddings=embeddings) response = dbqa({'query': args.input}) end = timeit.default_timer() print(f'\\nAnswer: {response[\"result\"]}') print('='*50) # Process source documents source_docs = response['source_documents'] for i, doc in enumerate(source_docs): print(f'\\nSource Document {i+1}\\n') print(f'Source Text: {doc.page_content}') print(f'Document Name: {doc.metadata[\"source\"]}') #print(f'Page Number: {doc.metadata[\"page\"]}\\n') print('='* 60) # print(f\"Time to retrieve response: {end - start}\") Bib Touvron, H. et al. (2023). Llama 2: Open Foundation and Fine-Tuned Chat Models. arXiv:2307.09288. https://arxiv.org/abs/2307.09288. Lewis, P. et al. (2021). Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. arXiv:2005.11401 https://arxiv.org/abs/2005.11401. Faiss is a library for efficient similarity search and clustering of dense vectors, https://github.com/facebookresearch/faiss. HuggingFace, https://huggingface.co/. Pic by @Luke Tanis ","date":"2023-09-01","objectID":"/documents_qa/:7:0","tags":["chatbot","llm","question-answering"],"title":"Retrieval-augmented generation for Chatbot","uri":"/documents_qa/"},{"categories":["Responsible AI"],"content":"Responsible AI has become a crucial aspect of every Machine Learning project, underscoring the need for tools that promote the creation of fair and ethically sound models. In this post, we delve into some key concepts and replicate IBM’s inFairness example solution to address bias in the ‘Adult Income’ dataset. Beyond the technical configurations adopted, the intent to algorithmically address unfairness and the statistical pursuit of both overt and hidden bias in data are particularly noteworthy. These are the key insights we hope readers will take away from this post. ","date":"2023-06-01","objectID":"/responsible_ai/:0:0","tags":["fairness","bias","neural networks"],"title":"Responsible AI Tools","uri":"/responsible_ai/"},{"categories":["Responsible AI"],"content":"Unfearness and Responsible AI The pervasive application of machine learning in many sensitive environments to make important and life-changing decisions, has heightened concerns about the fairness and ethical impact of these technologies. More importantly, experiments that unveil biases and disparities inherent in these implementations (Mehrabi, 2022) have dismantled the idea of algorithmic ’neutrality’, emphasizes the critical need for alignment with laws and values pertaining to human dignity. In this context, the concept of responsible AI has emerged as a crucial component of every AI project, underscoring the need for procedures that can facilitate the creation of safe, fair, and ethically grounded tools (Richardson, 2021). ","date":"2023-06-01","objectID":"/responsible_ai/:1:0","tags":["fairness","bias","neural networks"],"title":"Responsible AI Tools","uri":"/responsible_ai/"},{"categories":["Responsible AI"],"content":"Fair AI tools We can view the concept of fair AI tools as pointing to software that is free from unintentional algorithmic bias. Fairness, as defined by Mehrabi et al. (2021), is the absence of any prejudice or favoritism toward an individual or a group based on their inherent or acquired characteristics. What is the difference between individual and group fairness? ","date":"2023-06-01","objectID":"/responsible_ai/:2:0","tags":["fairness","bias","neural networks"],"title":"Responsible AI Tools","uri":"/responsible_ai/"},{"categories":["Responsible AI"],"content":"Individual an Group Fairness A brief overview of the concepts of individual and group fairness as defined by Dwork et al. in their 2011 paper “Fairness Through Awareness.” Individual Fairness: According to Dwork et al., individual fairness is the principle that similar individuals should be treated similarly. This means that an algorithm is individually fair if it gives similar outputs for similar inputs. The definition of “similarity” can vary depending on the context, but it is generally defined in terms of a metric or distance function over the input space. The formal definition of individual fairness is as follows: Given a metric space (X, d) and a function f: X → Y, we say that f is Lipschitz if for all x, x’ ∈ X, d_Y(f(x), f(x’)) ≤ d_X(x, x’). In the context of fairness, this means that the difference in the outputs of the function (i.e., the decisions made by the algorithm) should not be greater than the difference in the inputs (i.e., the individuals being considered). Group Fairness: Group fairness, on the other hand, is the principle that different groups should be treated similarly on average. This means that an algorithm is group-fair if it gives similar outcomes for different groups, even if the individuals within those groups are not similar. The formal definition of group fairness can vary depending on the specific notion of fairness being considered (e.g., demographic parity, equal opportunity, etc.). However, a common definition is that the decision rates (i.e., the proportion of positive outcomes) should be equal for different groups. For example, if we denote by P(Y=1|A=a) the probability of a positive outcome given group membership a, then demographic parity requires that P(Y=1|A=a) = P(Y=1|A=a’) for all groups a, a'. To achieve fairness-related goals, we can approach them through both product development and the implementation of specific procedures: Products: refers to AI software that is designed and developed with fairness in mind. This could involve algorithms that mitigate bias or tools that promote transparency in AI decision-making. Regarding solutions, Richardson asserts that fair AI consists of strategies to combat algorithmic bias. These often include top-tier solutions drawn from research in explainability, transparency, interpretability, and accountability (Richardson, 2021). Procedures: refers to standardized activities or practices that ensure fairness. This could include ethical guidelines for AI development, rigorous testing for bias in AI systems, and policies for responsible AI use. It’s important to note that the specifics of these ‘products’ and ‘procedures’ can vary significantly depending on the context, the specific AI application, and the definition of ‘fairness’ in use. Fairness is a time-bound and context-dependent moral concept, so tools designed to ensure it must adapt to evolving standards. This means they must be flexible to changes in societal values and expectations over time. That is why the pursuit of fair AI tools is a continuous and context-specific endeavor, which rules out the possibility of universally applicable or one-size-fits-all solutions. As stated in Fairlearn project (Microsoft): ‘because there are many complex sources of unfairness—some societal and some technical—it is not possible to fully “debias” a system or to guarantee fairness; the goal is to mitigate fairness-related harms as much as possible.’ ","date":"2023-06-01","objectID":"/responsible_ai/:3:0","tags":["fairness","bias","neural networks"],"title":"Responsible AI Tools","uri":"/responsible_ai/"},{"categories":["Responsible AI"],"content":"A fair tool: InFairness Now, let’s turn into a practical application of fairness in AI. We will be testing the ‘fair-ml’ algorithms developed by IBM Research, available in their inFairness package. These algorithms are designed with a focus on fairness, guided by the fairness metric proposed by Dwork et al., 2011. To explore these implementation we will follow the model example provided in the package. We are going to work with Adult dataset (Dua \u0026 Graff, 2017) used to predict whether income exceeds $50K/yr based on census data. Also known as “Census Income” dataset Train dataset contains 13 features and 30178 observations. Test dataset contains 13 features and 15315 observations. Target column is a binary factor where 1: \u003c=50K and 2: \u003e50K for annual income. ","date":"2023-06-01","objectID":"/responsible_ai/:4:0","tags":["fairness","bias","neural networks"],"title":"Responsible AI Tools","uri":"/responsible_ai/"},{"categories":["Responsible AI"],"content":"Libraries import torch import torch.nn as nn import torch.nn.functional as F from tqdm.auto import tqdm from inFairness.fairalgo import SenSeI from inFairness import distances from inFairness.auditor import SenSRAuditor, SenSeIAuditor %load_ext autoreload %autoreload 2 import metrics ","date":"2023-06-01","objectID":"/responsible_ai/:4:1","tags":["fairness","bias","neural networks"],"title":"Responsible AI Tools","uri":"/responsible_ai/"},{"categories":["Responsible AI"],"content":"Bias exploration import pandas as pd url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data' names = [ 'age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'annual-income' ] data = pd.read_csv(url, sep=',', names=names) What are the 'Adult' dataset features? data.head() age workclass fnlwgt education education-num marital-status occupation relationship race sex capital-gain capital-loss hours-per-week native-country annual-income 0 39 State-gov 77516 Bachelors 13 Never-married Adm-clerical Not-in-family White Male 2174 0 40 United-States \u003c=50K 1 50 Self-emp-not-inc 83311 Bachelors 13 Married-civ-spouse Exec-managerial Husband White Male 0 0 13 United-States \u003c=50K 2 38 Private 215646 HS-grad 9 Divorced Handlers-cleaners Not-in-family White Male 0 0 40 United-States \u003c=50K 3 53 Private 234721 11th 7 Married-civ-spouse Handlers-cleaners Husband Black Male 0 0 40 United-States \u003c=50K 4 28 Private 338409 Bachelors 13 Married-civ-spouse Prof-specialty Wife Black Female 0 0 40 Cuba \u003c=50K data['annual-income'].value_counts() annual-income \u003c=50K 24720 \u003e50K 7841 Name: count, dtype: int64 The dataset is imbalanced: 25% make at least $50k per year. This imbalanced also appears in sex and race as shown here: (imbal_sex := data.groupby(['annual-income', 'sex']).size() .sort_values(ascending=False) .reset_index(name='count') .assign(percentage = lambda df:100 * df['count']/df['count'].sum()) ) annual-income sex count percentage 0 \u003c=50K Male 15128 46.460490 1 \u003c=50K Female 9592 29.458555 2 \u003e50K Male 6662 20.460060 3 \u003e50K Female 1179 3.620896 (imbal_race := data.groupby(['annual-income', 'race']).size() .sort_values(ascending=False) .reset_index(name='count') .assign(percentage = lambda df:100 * df['count']/df['count'].sum()) ) annual-income race count percentage 0 \u003c=50K White 20699 63.569915 1 \u003e50K White 7117 21.857437 2 \u003c=50K Black 2737 8.405761 3 \u003c=50K Asian-Pac-Islander 763 2.343294 4 \u003e50K Black 387 1.188538 5 \u003e50K Asian-Pac-Islander 276 0.847640 6 \u003c=50K Amer-Indian-Eskimo 275 0.844569 7 \u003c=50K Other 246 0.755505 8 \u003e50K Amer-Indian-Eskimo 36 0.110562 9 \u003e50K Other 25 0.076779 ","date":"2023-06-01","objectID":"/responsible_ai/:4:2","tags":["fairness","bias","neural networks"],"title":"Responsible AI Tools","uri":"/responsible_ai/"},{"categories":["Responsible AI"],"content":"Simple neural network model Folowing the IBM example in the income prediction task, we will test a simple neural network. class AdultDataset(Dataset): def __init__(self, data, labels): self.data = data self.labels = labels def __getitem__(self, idx): data = self.data[idx] label = self.labels[idx] return data, label def __len__(self): return len(self.labels) Note that the categorical variable are transformed into one-hot variables. import data train_df, test_df = data.load_data() X_train_df, Y_train_df = train_df X_test_df, Y_test_df = test_df X_train_df.head(1) age capital-gain capital-loss education-num hours-per-week marital-status_Divorced marital-status_Married-AF-spouse marital-status_Married-civ-spouse marital-status_Married-spouse-absent marital-status_Never-married ... relationship_Unmarried relationship_Wife sex_Male workclass_Federal-gov workclass_Local-gov workclass_Private workclass_Self-emp-inc workclass_Self-emp-not-inc workclass_State-gov workclass_Without-pay 0 0.409331 -0.14652 -0.218253 -1.613806 -0.49677 False False False False True ... True False False False False True False False False False In the IBM-inFairness model example the protected attributes are dropped from the training and test data. That is usually the case in fairness-aware machine learning models,especially when dealing with known biased features. The aim is to prevent the model from directly using these sensitive attributes for decision-making, thereby avoiding potential discriminatory outcomes. However, this approach has some limitations. Even when the protected attributes are removed, other features in the dataset might act as proxies for it, potentially retaining a strong signal of the biased information. As an example certain occupations, neighborhoods, or education levels might be disproportionately associated with certain racial groups due to societal factors. So, even without explicit information about race, the model might still end up learning patterns that indirectly reflect racial biases. On the other hand, removing sensitives attributes makes it difficult to analyze the fairness of the model. If we don’t know the race of the individuals in our dataset, we can’t check whether our model is treating individuals of different races equally. In some cases, it’s important to consider sensitive attributes to ensure fairness. For example, in order to correct for historical biases or to achieve certain diversity and inclusion goals, it might be necessary to consider these attributes. So, while removing sensitive attributes might seem like an easy fix, it doesn’t necessarily solve the problem of bias and might introduce new problems. Instead, it’s often better to use techniques that aim to ensure that the model treats similar individuals similarly (individual fairness), regardless of their sensitive attributes. protected_vars = ['race_White', 'sex_Male'] X_protected_df = X_train_df[protected_vars] X_train_df = X_train_df.drop(columns=protected_vars) X_test_df = X_test_df.drop(columns=protected_vars) In assessing individual fairness, the example we are working with implements a variable consistency measure using the ‘spouse’ attribute. This involves flipping the ‘spouse’ variable in the dataset, essentially simulating a scenario where individuals with the same characteristics but different ‘spouse’ values are compared. The goal is to ensure that the model’s predictions are consistent for individuals who are similar except for their ‘spouse’ attribute, thereby upholding the principle of individual fairness. This approach provides a practical way to audit the model’s fairness by checking if similar individuals are treated similarly. X_test_df.relationship_Wife.values.astype(int) array([0, 1, 0, ..., 0, 0, 0]) X_test_df_spouse_flipped = X_test_df.copy() X_test_df_spouse_flipped.relationship_Wife = 1 - X_test_df_spouse_flipped.relationship_Wife X_test_df_spouse_flipped.relationship_Wife.values array([1, 0, 1, ..., 1, 1, 1]) device = torch.devic","date":"2023-06-01","objectID":"/responsible_ai/:4:3","tags":["fairness","bias","neural networks"],"title":"Responsible AI Tools","uri":"/responsible_ai/"},{"categories":["Responsible AI"],"content":"Standard training input_size = X_train.shape[1] output_size = 2 network_standard = Model(input_size, output_size).to(device) optimizer = torch.optim.Adam(network_standard.parameters(), lr=1e-3) loss_fn = F.cross_entropy EPOCHS = 10 network_standard.train() for epoch in tqdm(range(EPOCHS)): for x, y in train_dl: x, y = x.to(device), y.to(device) optimizer.zero_grad() y_pred = network_standard(x).squeeze() loss = loss_fn(y_pred, y) loss.backward() optimizer.step() 100%|██████████| 10/10 [00:08\u003c00:00, 1.24it/s] accuracy = metrics.accuracy(network_standard, test_dl, device) balanced_acc = metrics.balanced_accuracy(network_standard, test_dl, device) spouse_consistency = metrics.spouse_consistency(network_standard, test_dl, test_dl_flip, device) print(f'Accuracy: {accuracy}') print(f'Balanced accuracy: {balanced_acc}') print(f'Spouse consistency: {spouse_consistency}') Accuracy: 0.8555948734283447 Balanced accuracy: 0.7764129391420478 Spouse consistency: 0.9636222910216719 The simple NN achieve .85 of accuracy. However, the inconsistency score of 0.04 on the ‘spouse’ variable suggests that the model is not treating similar individuals consistently, which is a violation of individual fairness. This inconsistency could be due to the fact that the model is learning to differentiate based on gender, despite the intention to avoid such bias. ","date":"2023-06-01","objectID":"/responsible_ai/:4:4","tags":["fairness","bias","neural networks"],"title":"Responsible AI Tools","uri":"/responsible_ai/"},{"categories":["Responsible AI"],"content":"Individually fair training with LogReg fair metric In the following section, a fair machine learning model is introduced. This model is said to be fair because its performance remains consistent under certain perturbations within a sensitive subspace, meaning it is robust to partial data variations. To illustrate the authors’ approach, let’s consider the process of evaluating the fairness of a resume screening system. An auditor might alter the names on resumes of applicants from the ethnic majority group to those more commonly found among the ethnic minority group. If the system’s performance declines upon reviewing the altered resumes (i.e., the evaluations become less favorable), one could infer that the model exhibits bias against applicants from the ethnic minority group. To algorithmically address this issue, the authors propose a method to instill individual fairness during the training of ML models. This is achieved through distributionally robust optimization (DRO), an optimization technique that seeks the optimal solution while considering a fairness metric (inspired by Adversarial Robustness). ","date":"2023-06-01","objectID":"/responsible_ai/:4:5","tags":["fairness","bias","neural networks"],"title":"Responsible AI Tools","uri":"/responsible_ai/"},{"categories":["Responsible AI"],"content":"Learning fair metric from data and its hidden signals The authors use Wasserstein distances to measure the similarity between individuals. Unlike Mahalanobis, Wasserstein distance can be used to compare two probability distributions and is defined as the minimum cost that must be paid to transform one distribution into the other. The distances between data points are calculated in a way that takes into account protected attributes (in our example: gender or race). The goal is to ensure that similar individuals, as determined by Wasserstein distance, are treated similarly by the machine learning model. To achieve this, the algorithm learn ‘sensitive directions’ in the data. These are directions in the feature space along which changes are likely to correspond to changes in protected attributes. These is a clever approach to uncover hidden biases by identifying subtle patterns that may correspond to changes in protected attributes, even if those attributes are not present in our model inputs. This allows the model to account for potential biases that might otherwise go unnoticed. For instance, to identify a sensitive direction associated with a particular attribute (e.g., gender), the algorithm use a logistic regression classifier to distinguish between classes (such as men and women in the data). The coefficients from this logistic regression model define a direction within the feature space. The performance of the machine learning model is assessed by its worst-case performance on hypothetical populations of users with perturbed sensitive attributes. By minimizing the loss function, the system is ensured to perform well on all such populations. # Same architecture we found network_fair_LR = Model(input_size, output_size).to(device) optimizer = torch.optim.Adam(network_fair_LR.parameters(), lr=1e-3) lossfn = F.cross_entropy # set the distance metric for instances similiraty detections distance_x_LR = distances.LogisticRegSensitiveSubspace() distance_y = distances.SquaredEuclideanDistance() # train fair metric distance_x_LR.fit(X_train, data_SensitiveAttrs=X_protected) distance_y.fit(num_dims=output_size) distance_x_LR.to(device) distance_y.to(device) rho = 5.0 eps = 0.1 auditor_nsteps = 100 auditor_lr = 1e-3 fairalgo_LR = SenSeI(network_fair_LR, distance_x_LR, distance_y, lossfn, rho, eps, auditor_nsteps, auditor_lr) ","date":"2023-06-01","objectID":"/responsible_ai/:4:6","tags":["fairness","bias","neural networks"],"title":"Responsible AI Tools","uri":"/responsible_ai/"},{"categories":["Responsible AI"],"content":"A fair objective function The objective function that is minimized during the training of a fair machine learning model as proposed in the inFairness package is composed of two parts: the loss function and the fair metric (see SenSeI): fair_loss = torch.mean( #--------1------------- + -----------------2-----------------------------# self.loss_fn(Y_pred, Y) + self.rho * self.distance_y(Y_pred, Y_pred_worst) ) Loss Function: a classical loss function that measure of how well the model’s predictions match the actual data. The goal of this metric is to adjust the model’s parameters to minimize the loss score, and Fair Metric (DIF): the fairness term is a measure of the difference between the model’s predictions on the original data and its predictions on the worst-case examples. The model is trying to minimize this objective function, which means it’s trying to make accurate and fair predictions. It’s important to note that due to the computation of a complex loss score, the training process becomes more resource-intensive. fairalgo_LR.train() for epoch in tqdm(range(EPOCHS)): for x, y in train_dl: x, y = x.to(device), y.to(device) optimizer.zero_grad() result = fairalgo_LR(x, y) result.loss.backward() optimizer.step() 100%|██████████| 10/10 [10:09\u003c00:00, 60.90s/it] accuracy = metrics.accuracy(network_fair_LR, test_dl, device) balanced_acc = metrics.balanced_accuracy(network_fair_LR, test_dl, device) spouse_consistency = metrics.spouse_consistency(network_fair_LR, test_dl, test_dl_flip, device) print(f'Accuracy: {accuracy}') print(f'Balanced accuracy: {balanced_acc}') print(f'Spouse consistency: {spouse_consistency}') Accuracy: 0.8401150107383728 Balanced accuracy: 0.742399333699871 Spouse consistency: 0.9997788589119858 ","date":"2023-06-01","objectID":"/responsible_ai/:4:7","tags":["fairness","bias","neural networks"],"title":"Responsible AI Tools","uri":"/responsible_ai/"},{"categories":["Responsible AI"],"content":"Results # Auditing using the SenSR Auditor + LR metric audit_nsteps = 1000 audit_lr = 0.1 auditor_LR = SenSRAuditor(loss_fn=loss_fn, distance_x=distance_x_LR, num_steps=audit_nsteps, lr=audit_lr, max_noise=0.5, min_noise=-0.5) audit_result_stdmodel = auditor_LR.audit(network_standard, X_test, y_test, lambda_param=10.0, audit_threshold=1.15) audit_result_fairmodel_LR = auditor_LR.audit(network_fair_LR, X_test, y_test, lambda_param=10.0, audit_threshold=1.15) print(\"=\"*100) print(\"LR metric\") print(f\"Loss ratio (Standard model) : {audit_result_stdmodel.lower_bound}. Is model fair: {audit_result_stdmodel.is_model_fair}\") print(f\"Loss ratio (fair model - LogReg metric) : {audit_result_fairmodel_LR.lower_bound}. Is model fair: {audit_result_fairmodel_LR.is_model_fair}\") LR metric Loss ratio (Standard model) : 2.1810670575586046. Is model fair: False Loss ratio (fair model - LogReg metric) : 1.0531351204682995. Is model fair: True Findings Upon reviewing the overall results, we see that with a minor decrease in accuracy of 0.01, we have successfully constructed a fair model that is debiased with respect to gender and race. ","date":"2023-06-01","objectID":"/responsible_ai/:4:8","tags":["fairness","bias","neural networks"],"title":"Responsible AI Tools","uri":"/responsible_ai/"},{"categories":["Responsible AI"],"content":"Conclusion We’ve explored a specific example of a fair-ML model using the tools provided by the inFairness package. While the results are promising, it’s important to contextualize them within the broader challenges of responsible AI, particularly given the rapid evolution of ML tools and the dynamic nature of societal values. Following Richardson, we can mention: Conflicting Fairness Metrics: Measurement is always a political activity in the sense that we must select, define, and prioritize certain dimensions of reality, setting aside others. Friedler et al. (2021) argue that fairness experts must explicitly state the priorities of each fairness metric to ensure practitioners make informed choices. Metric Robustness: Friedler et al. (2018) discovered that many fairness metrics lack robustness. Their study showed that by simply modifying dataset composition and changing train-test splits, many fairness criteria lacked stability. Oversimplification of Fairness: A major concern in the literature is the emphasis on technical solutions to algorithmic bias, which is a socio-technical problem. Madaio et al. (2020) referred to the exclusive use of technical solutions as “ethics washing,” and Selbst et al. (2019) describe the failure to recognize that fairness cannot be solely achieved through mathematical formulation as the “formalism trap.” Operationalization of Ethical Concepts: A significant challenge for fair AI is translating ethical reflections into actionable products and procedures that practitioners and institutions can implement. This difficulty is not unique to the AI field but affects every aspect of human activity where there is a need for ethical actions. Bibliography ","date":"2023-06-01","objectID":"/responsible_ai/:5:0","tags":["fairness","bias","neural networks"],"title":"Responsible AI Tools","uri":"/responsible_ai/"},{"categories":["Responsible AI"],"content":"Bibliography Dwork, Cynthia, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Rich Zemel. “Fairness Through Awareness.” arXiv, November 28, 2011. https://doi.org/10.48550/arXiv.1104.3913. Mehrabi, Ninareh, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. “A Survey on Bias and Fairness in Machine Learning.” arXiv, January 25, 2022. https://doi.org/10.48550/arXiv.1908.09635. Richardson, Brianna, and Juan E. Gilbert. “A Framework for Fairness: A Systematic Review of Existing Fair AI Solutions.” arXiv, December 10, 2021. https://doi.org/10.48550/arXiv.2112.05700. Weerts, Hilde, Miroslav Dudík, Richard Edgar, Adrin Jalali, Roman Lutz, and Michael Madaio. “Fairlearn: Assessing and Improving Fairness of AI Systems.” arXiv, March 29, 2023. https://doi.org/10.48550/arXiv.2303.16626. Bird, Sarah., Dudík, Miro., Edgar, Richard., Horn, Brandon., Lutz, Roman., Milan, Vanessa., Sameki, Mehrnoosh., Wallach, Hanna., \u0026 Walker, Kathleen. “Fairlearn: A toolkit for assessing and improving fairness in AI.” Microsoft, May 2020. https://www.microsoft.com/en-us/research/publication/fairlearn-a-toolkit-for-assessing-and-improving-fairness-in-ai. Floridi, Luciano., Cowls, Josh., Beltrametti, Monica., Chatila, Raja., Chazerand, Patrice., Dignum, Virginia., Luetge, Christoph., Madelin, Robert., Pagallo, Ugo., Rossi, Francesca., Schafer, Burkhard., Valcke, Peggy., \u0026 Vayena, Effy. “AI4People—An Ethical Framework for a Good AI Society: Opportunities, Risks, Principles, and Recommendations.” Minds and Machines, December 1, 2018. https://doi.org/10.1007/s11023-018-9482-5. Weerts, Hilde, Miroslav Dudík, Richard Edgar, Adrin Jalali, Roman Lutz, and Michael Madaio. “Fairlearn: Assessing and Improving Fairness of AI Systems.” arXiv, March 29, 2023. https://doi.org/10.48550/arXiv.2303.16626. Yurochkin, Mikhail, Amanda Bower, and Yuekai Sun. “Training Individually Fair ML Models with Sensitive Subspace Robustness.” arXiv, March 13, 2020. http://arxiv.org/abs/1907.00020. Pic by Patrick Fore, Unsplash ","date":"2023-06-01","objectID":"/responsible_ai/:6:0","tags":["fairness","bias","neural networks"],"title":"Responsible AI Tools","uri":"/responsible_ai/"},{"categories":["Dashboards","Data Driven Dulture"],"content":"This post chronicles the transformative journey that the Judiciary of Entre Ríos, Argentina, where I serve as Director, is undertaking in the realm of statistics. ","date":"2016-12-01","objectID":"/analitics_in_judiciary/:0:0","tags":["judiciary","public service"],"title":"Justice Analitics","uri":"/analitics_in_judiciary/"},{"categories":["Dashboards","Data Driven Dulture"],"content":"2016 Creation of a Specialized Body The Area of Planning, Management and Statistics, created in June 2016, undertook the project of reforming the judicial statistics of the province, beset by serious difficulties, through a profound change in working tools and more broadly in organizational culture (i.e. from the digitization of information and the design of new indicators, to the creation of a new calendar of statistical processes and internal regulations). It had the collaboration of magistrates and officials from all over the province who provided the substantive knowledge necessary for the generation of reliable judicial metrics. Despite limitations in tools and staff, efficient solutions were implemented, such as the use of the open-source software R-Statistical Computing for data processing. In a span of 10 months, judicial statistics were revolutionized, optimizing report production times, introducing new indicators, and launching a new Public Judicial Statistics System, which extended to all branches of provincial justice by June 2018 (more info). ","date":"2016-12-01","objectID":"/analitics_in_judiciary/:1:0","tags":["judiciary","public service"],"title":"Justice Analitics","uri":"/analitics_in_judiciary/"},{"categories":["Dashboards","Data Driven Dulture"],"content":"2019 Public Dashboards After two challenging years of work, the Statistics Dashboards of the Judicial Power of Entre Ríos were made available online. On December 17, 2019, the provincial justice system presented to society a public access tool to judicial indicators based on a formal production system, entirely supported by the open-source software R-Statistical Computing. Statistics Dashboards With this presentation, the team I was fortunate to lead fulfilled a long-sought goal in terms of open judicial data, creating along the way a unique model of judicial statistics in Argentina (more info). ","date":"2016-12-01","objectID":"/analitics_in_judiciary/:2:0","tags":["judiciary","public service"],"title":"Justice Analitics","uri":"/analitics_in_judiciary/"},{"categories":["Dashboards","Data Driven Dulture"],"content":"2021 Judicial Activity in COVID19 Pandemic I made a brief internal presentation on the impact of the Covid-19 Pandemic on judicial activity, with some details about the number of processes carried out between 2020 and 2021, which had a significant impact as it dispelled doubts about the activity of justice and the importance of its services (more info). After that, I gave a presentation on local television about the situation of the Judiciary during the sanitary isolation of the Pandemic: Finally, by the end of that year, we were already sharing our statistical transformation experience with all Judicial Powers in our country, gathered in the Federal Council of Courts and Superior Courts of Argentina (more info). ","date":"2016-12-01","objectID":"/analitics_in_judiciary/:3:0","tags":["judiciary","public service"],"title":"Justice Analitics","uri":"/analitics_in_judiciary/"},{"categories":null,"content":"The aplications that I've build","date":"2019-08-02","objectID":"/aplications/","tags":null,"title":"Aplications and Tools","uri":"/aplications/"},{"categories":null,"content":"News Analytic Tool In today’s fast-paced digital age, staying updated with the latest news and insights is crucial. I build a News Analytic System to provide users with enriched, insightful, and customized reports from targeted news portals and sources. pic: Filip Mishevski Features Web Scraping Module: To extract and gather news content from targeted portals and source pages. (Features: automated scraping schedules, resilient to website structure changes, captures multimedia content, including images and videos). Enriched Document Database: process and store news content in an enriched format for advanced analytics. (Features: embeddings representation for similarity and clustering analysis, summarization, Named Entity Recognition, relationships between identified entities for contextual understanding). Custom Report Generator: provide users with tailored reports based on their specific criteria. (Features: search by topics, persons, locations, or any custom criteria, automated report generation schedules, visually appealing report templates with charts, graphs, and images). Key Benefits  Up-to-date Information ensures users always have the latest news at their fingertips.  Insightful Analysis goes beyond mere news aggregation by providing deep insights and context.  Customization Tailored reports mean users only see what’s relevant to them.  Time-saving automated processes reduce the time spent on manual news curation and analysis. ","date":"2019-08-02","objectID":"/aplications/:1:0","tags":null,"title":"Aplications and Tools","uri":"/aplications/"},{"categories":null,"content":"Justice Dashboard The Justice Dashboard is the online service of the Supreme Court of Entre Ríos, Argentina, to access primary data and justice statistics. It is based on free software R and Shiny and follows the standards of the open data movement. The central part of the system, the statistical scripts, are accessible in operations, proccesing, organization and research. Justice Data ","date":"2019-08-02","objectID":"/aplications/:2:0","tags":null,"title":"Aplications and Tools","uri":"/aplications/"},{"categories":null,"content":"Features  Optimized for public access and reproducibility of statistics.  Compliance with national and international standards on public information and sensitive data.  Full user access of algorithms and scripts. ","date":"2019-08-02","objectID":"/aplications/:2:1","tags":null,"title":"Aplications and Tools","uri":"/aplications/"},{"categories":null,"content":"Airports Worldwide The Airports Worldwide app is a pet-project developed for the Universidad Tecnológica Nacional, Visualizations seminar, embodying a database of airports around the globe. Build with Python and Dash, it presents an interactive and user-friendly interface for users to explore the data. It is deploy on Heroku. Airports ","date":"2019-08-02","objectID":"/aplications/:3:0","tags":null,"title":"Aplications and Tools","uri":"/aplications/"},{"categories":null,"content":"Features  Worlwide Database: The application provides information about airports worldwide. Users can access specifics information as location, airport size and more.  Interactive: the application enabling users to visualize the geographical distribution of airports across the world. Users can zoom in and out to view airports in specific regions or countries, making it easy to understand global airport infrastructure. ","date":"2019-08-02","objectID":"/aplications/:3:1","tags":null,"title":"Aplications and Tools","uri":"/aplications/"},{"categories":null,"content":"Predictive Modeling in Justice The Predictive Modeling Series (Parts: 1, 2, 3 and 4) showcases our development of models for time series data in judicial services.Our aim is to predict the number of rulings per subject matter over a specified period. For this project, we’ve exclusively utilized R, specifically leveraging the tidymodels package. pic: Aron Visuals ","date":"2019-08-02","objectID":"/aplications/:4:0","tags":null,"title":"Aplications and Tools","uri":"/aplications/"},{"categories":null,"content":"Features  The complete scripts of this implementation can be accessed here. ","date":"2019-08-02","objectID":"/aplications/:4:1","tags":null,"title":"Aplications and Tools","uri":"/aplications/"}]