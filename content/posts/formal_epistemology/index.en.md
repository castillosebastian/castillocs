---
weight: 1
title: "Formal Epistemology"
date: 2015-03-25T10:49:29-03:00
lastmod: 2015-03-06T21:29:01+08:00
draft: true
images: []
resources:
- name: "featured-image"
  src: "featured-image.jpg"
- name: "featured-image-preview"
  src: "featured-image-preview.jpg"

tags: ["Knowledge"]
categories: ["Formal Epistemology"]
lightgallery: true
toc:
  auto: false
---

Formal epistemology is an interdisciplinary field that reflects on knowledge and learning using formal methods. 

<!--more-->


## Test components

```python
a = 2+2 
print("Hello")
```

{{< admonition type=info title="Formal Epistemologoy" open=false >}}
Formal epistemology reflects on knowledge and learning using formal methods. These methods not only include tools that come from logic and mathematics,[^Weinsberg] but also - and today more than ever - from computing, particularly developments in the field of artificial intelligence. This commits the reflection methodologically to certain procedures, seeking results with a level of abstraction useful for understanding complex phenomena such as knowledge and learning. Formal approach simplifies the elements and relationships under analysis, allowing epistemological problems to be productively modeled.
[^Weinsberg]: Weisberg, Jonathan, "Formal Epistemology", The Stanford Encyclopedia of Philosophy (Winter 2017 Edition), Edward N. Zalta (ed.), URL = <https://plato.stanford.edu/archives/win2017/entries/formal-epistemology/>.  
{{< /admonition >}}


{{< admonition type=info title="Learning" open=false >}}
Schulte notes that many results in the field of formal learning in Computer Science are linked to the notion of Valiant and Vapnik on *learning of approximately correct generalizations from a probability perspective*.[^Schulte] The *approach to correction* is closely linked to the notion of *empirical success* introduced by Gilbert Harmann, and revisited by Valiant in his reflection on the problems of induction (Valiant, 2013, Ch. 5). In any case, formal learning generally refers to a contextualized epistemological analysis where a specific empirical problem and an expected outcome in terms of learning are highlighted. This is why Schulte points out that **the majority of [formal] learning theories examine which research strategies are most reliable and efficient in generating beliefs [knowledge] about the world.** 
[^Schulte]: Schulte, Oliver, "Formal Learning Theory", The Stanford Encyclopedia of Philosophy (Spring 2018 Edition), Edward N. Zalta (ed.), URL = <https://plato.stanford.edu/archives/spr2018/entries/learning-formal/>.
{{< /admonition >}}


{{< admonition type=info title="Deep Learning" open=false >}}
Deep Learning (DL) is a technique by which an agent acquires the ability to 'learn' from experience stored in the form of data. This technique is part of the field of Artificial Intelligence which, in general terms, seeks to create agents capable of performing tasks that involve complex intellectual skills, tasks such as recognizing images, processing and producing language, identifying patterns, among others. At the heart of DL is the old epistemological problem of generating 'good representations' of knowledge objects; a problem that DL solves by **representing the world as a hierarchical structure of nested concepts, where each concept is defined in relation to simpler concepts, and where the more abstract representations are computed from less abstract ones** (Goodfellow et al. 2016:8). For this reason, one of the important tasks of DL is the algorithmic transformation of concepts from simple units into complex units.
To generate representations of objects, and unlike other formal learning techniques, DL has the ability to identify defining characteristics of certain objects (*features*) and generate models (representations) from them. This ability to generate models is autonomous in a strict sense: DL does not have previous models of its objects, it constructs them using mathematical functions. To establish an analogy with humans, we might think that until not long ago, only a person could look at 10,000 photos of chairs and create a model to recognize whether a new photo (the 10,001st) is a chair or not. Now an agent that applies DL can do the same, in an amazingly fast and provenly more effective way.
The 'learning of representations' is a defining aspect of DL, and implies a simultaneous task of identifying distinctive features of objects by isolating them from particular variation factors always present in experience. For this, DL generates its complex representations (the chair model) by composing them from simple representations. The notion of 'deep learning' comes from the fact that this composition takes the form of processing at levels or layers of information.(Chollet-Allaire, Deep Learning with R, 2017.)
{{< /admonition >}}